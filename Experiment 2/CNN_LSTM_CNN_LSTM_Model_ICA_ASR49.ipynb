{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the preprocessed data\n",
    "X = np.load('X_all_ICA_ASR49.npy')\n",
    "Y = np.load('Y_all_ICA_ASR49.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (2098, 22, 1126)\n",
      "Validation set shape: (234, 22, 1126)\n",
      "Test set shape: (260, 22, 1126)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=.1,random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed)  # Split train into train (85%) and validation (15%)\n",
    "\n",
    "X_train_flatten = X_train.reshape(-1, X_train.shape[-1])  # Shape: (num_train_epochs * num_channels, seq_len)\n",
    "X_val_flatten = X_val.reshape(-1, X_val.shape[-1])        # Validation set\n",
    "X_test_flatten = X_test.reshape(-1, X_test.shape[-1])  # Shape: (num_test_epochs * num_channels, seq_len)\n",
    "\n",
    "mean = X_train_flatten.mean(axis=0)  # Compute the mean for each feature\n",
    "X_train_centered = X_train_flatten - mean\n",
    "X_val_centered = X_val_flatten - mean  # Center validation data using train set mean\n",
    "X_test_centered = X_test_flatten - mean  # Apply the same mean to X_test\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # Disable mean subtraction since we already did it\n",
    "X_train_scaled = scaler.fit_transform(X_train_centered)  # Fit on X_train\n",
    "X_val_scaled = scaler.transform(X_val_centered)  # Apply the same scaler to validation data\n",
    "X_test_scaled = scaler.transform(X_test_centered)  # Transform X_test using the same scaler\n",
    "\n",
    "X_train_final = X_train_scaled.reshape(X_train.shape)  # Shape: (num_train_epochs, num_channels, seq_len)\n",
    "X_val_final = X_val_scaled.reshape(X_val.shape)        # Shape: (num_val_epochs, num_channels, seq_len)\n",
    "X_test_final = X_test_scaled.reshape(X_test.shape)  # Shape: (num_test_epochs, num_channels, seq_len)\n",
    "\n",
    "print(\"Train set shape:\", X_train_final.shape)\n",
    "print(\"Validation set shape:\", X_val_final.shape)\n",
    "print(\"Test set shape:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert Numpy Arrays to PyTorch Tensors\n",
    "X_train1=torch.tensor(X_train_final,dtype=torch.float32)\n",
    "X_val1=torch.tensor(X_val_final,dtype=torch.float32)\n",
    "X_test1=torch.tensor(X_test_final,dtype=torch.float32)\n",
    "\n",
    "y_train1=torch.tensor(y_train,dtype=torch.long)\n",
    "y_val1=torch.tensor(y_val,dtype=torch.long)\n",
    "y_test1=torch.tensor(y_test,dtype=torch.long)\n",
    "\n",
    "# 2. Create TensorDatasets for Train, Validation, and Test Sets\n",
    "train_dataset=TensorDataset(X_train1,y_train1)\n",
    "val_dataset=TensorDataset(X_val1,y_val1)\n",
    "test_dataset=TensorDataset(X_test1,y_test1)\n",
    "\n",
    "# 3. Create DataLoaders for Batch Processing\n",
    "train_loader=DataLoader(train_dataset,batch_size=100,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=100,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Train Loss: 1.4431, Train Accuracy: 25.12%, Val Loss: 1.3695, Val Accuracy: 33.33%\n",
      "Epoch [2/250], Train Loss: 1.4355, Train Accuracy: 24.26%, Val Loss: 1.3574, Val Accuracy: 33.33%\n",
      "Epoch [3/250], Train Loss: 1.4113, Train Accuracy: 26.26%, Val Loss: 1.3553, Val Accuracy: 31.20%\n",
      "Epoch [4/250], Train Loss: 1.3966, Train Accuracy: 28.12%, Val Loss: 1.3551, Val Accuracy: 31.20%\n",
      "Epoch [5/250], Train Loss: 1.3856, Train Accuracy: 29.36%, Val Loss: 1.3349, Val Accuracy: 33.76%\n",
      "Epoch [6/250], Train Loss: 1.3760, Train Accuracy: 28.88%, Val Loss: 1.3210, Val Accuracy: 36.32%\n",
      "Epoch [7/250], Train Loss: 1.3540, Train Accuracy: 31.98%, Val Loss: 1.3189, Val Accuracy: 32.48%\n",
      "Epoch [8/250], Train Loss: 1.3472, Train Accuracy: 32.84%, Val Loss: 1.2932, Val Accuracy: 37.18%\n",
      "Epoch [9/250], Train Loss: 1.3162, Train Accuracy: 36.08%, Val Loss: 1.3125, Val Accuracy: 36.75%\n",
      "Epoch [10/250], Train Loss: 1.3124, Train Accuracy: 37.18%, Val Loss: 1.2549, Val Accuracy: 41.03%\n",
      "Epoch [11/250], Train Loss: 1.2880, Train Accuracy: 38.37%, Val Loss: 1.2256, Val Accuracy: 37.18%\n",
      "Epoch [12/250], Train Loss: 1.2517, Train Accuracy: 42.04%, Val Loss: 1.2234, Val Accuracy: 41.03%\n",
      "Epoch [13/250], Train Loss: 1.2551, Train Accuracy: 41.13%, Val Loss: 1.1673, Val Accuracy: 47.86%\n",
      "Epoch [14/250], Train Loss: 1.2189, Train Accuracy: 44.14%, Val Loss: 1.2013, Val Accuracy: 42.31%\n",
      "Epoch [15/250], Train Loss: 1.2049, Train Accuracy: 45.23%, Val Loss: 1.1763, Val Accuracy: 46.15%\n",
      "Epoch [16/250], Train Loss: 1.1972, Train Accuracy: 45.28%, Val Loss: 1.4313, Val Accuracy: 35.90%\n",
      "Epoch [17/250], Train Loss: 1.1929, Train Accuracy: 45.81%, Val Loss: 1.1157, Val Accuracy: 47.44%\n",
      "Epoch [18/250], Train Loss: 1.1620, Train Accuracy: 45.81%, Val Loss: 1.1672, Val Accuracy: 46.15%\n",
      "Epoch [19/250], Train Loss: 1.1299, Train Accuracy: 49.19%, Val Loss: 1.0702, Val Accuracy: 49.15%\n",
      "Epoch [20/250], Train Loss: 1.1456, Train Accuracy: 48.14%, Val Loss: 1.0452, Val Accuracy: 51.71%\n",
      "Epoch [21/250], Train Loss: 1.1234, Train Accuracy: 50.62%, Val Loss: 1.1255, Val Accuracy: 47.86%\n",
      "Epoch [22/250], Train Loss: 1.1200, Train Accuracy: 50.86%, Val Loss: 1.2025, Val Accuracy: 44.87%\n",
      "Epoch [23/250], Train Loss: 1.1124, Train Accuracy: 50.57%, Val Loss: 1.1048, Val Accuracy: 44.02%\n",
      "Epoch [24/250], Train Loss: 1.0734, Train Accuracy: 52.00%, Val Loss: 1.1513, Val Accuracy: 46.15%\n",
      "Epoch [25/250], Train Loss: 1.0800, Train Accuracy: 52.19%, Val Loss: 1.0705, Val Accuracy: 52.56%\n",
      "Epoch [26/250], Train Loss: 1.0813, Train Accuracy: 50.29%, Val Loss: 1.0091, Val Accuracy: 50.85%\n",
      "Epoch [27/250], Train Loss: 1.0669, Train Accuracy: 52.48%, Val Loss: 1.0456, Val Accuracy: 52.56%\n",
      "Epoch [28/250], Train Loss: 1.0627, Train Accuracy: 53.34%, Val Loss: 1.0209, Val Accuracy: 52.14%\n",
      "Epoch [29/250], Train Loss: 1.0286, Train Accuracy: 53.77%, Val Loss: 1.0451, Val Accuracy: 53.42%\n",
      "Epoch [30/250], Train Loss: 1.0396, Train Accuracy: 53.24%, Val Loss: 0.9701, Val Accuracy: 55.13%\n",
      "Epoch [31/250], Train Loss: 1.0208, Train Accuracy: 55.72%, Val Loss: 1.0073, Val Accuracy: 52.99%\n",
      "Epoch [32/250], Train Loss: 1.0218, Train Accuracy: 55.62%, Val Loss: 1.0906, Val Accuracy: 50.00%\n",
      "Epoch [33/250], Train Loss: 1.0071, Train Accuracy: 56.48%, Val Loss: 0.9858, Val Accuracy: 52.56%\n",
      "Epoch [34/250], Train Loss: 1.0034, Train Accuracy: 55.53%, Val Loss: 0.9611, Val Accuracy: 55.56%\n",
      "Epoch [35/250], Train Loss: 0.9932, Train Accuracy: 56.39%, Val Loss: 0.9464, Val Accuracy: 57.26%\n",
      "Epoch [36/250], Train Loss: 1.0095, Train Accuracy: 55.86%, Val Loss: 0.9446, Val Accuracy: 55.98%\n",
      "Epoch [37/250], Train Loss: 0.9837, Train Accuracy: 57.05%, Val Loss: 0.9392, Val Accuracy: 53.85%\n",
      "Epoch [38/250], Train Loss: 0.9985, Train Accuracy: 56.39%, Val Loss: 0.9269, Val Accuracy: 58.97%\n",
      "Epoch [39/250], Train Loss: 0.9724, Train Accuracy: 57.24%, Val Loss: 1.0189, Val Accuracy: 52.56%\n",
      "Epoch [40/250], Train Loss: 0.9762, Train Accuracy: 58.53%, Val Loss: 1.0417, Val Accuracy: 52.56%\n",
      "Epoch [41/250], Train Loss: 0.9973, Train Accuracy: 56.20%, Val Loss: 0.9868, Val Accuracy: 53.42%\n",
      "Epoch [42/250], Train Loss: 0.9676, Train Accuracy: 57.10%, Val Loss: 0.9501, Val Accuracy: 57.26%\n",
      "Epoch [43/250], Train Loss: 0.9379, Train Accuracy: 59.15%, Val Loss: 0.9588, Val Accuracy: 58.12%\n",
      "Epoch [44/250], Train Loss: 0.9292, Train Accuracy: 59.72%, Val Loss: 0.9546, Val Accuracy: 56.41%\n",
      "Epoch [45/250], Train Loss: 0.9480, Train Accuracy: 58.34%, Val Loss: 1.0279, Val Accuracy: 51.28%\n",
      "Epoch [46/250], Train Loss: 0.9235, Train Accuracy: 59.20%, Val Loss: 0.9460, Val Accuracy: 56.84%\n",
      "Epoch [47/250], Train Loss: 0.9486, Train Accuracy: 58.67%, Val Loss: 1.0482, Val Accuracy: 50.00%\n",
      "Epoch [48/250], Train Loss: 0.9249, Train Accuracy: 60.58%, Val Loss: 1.0738, Val Accuracy: 54.70%\n",
      "Epoch [49/250], Train Loss: 0.9089, Train Accuracy: 61.92%, Val Loss: 0.9207, Val Accuracy: 60.26%\n",
      "Epoch [50/250], Train Loss: 0.8877, Train Accuracy: 62.25%, Val Loss: 1.0088, Val Accuracy: 55.56%\n",
      "Epoch [51/250], Train Loss: 0.9125, Train Accuracy: 61.49%, Val Loss: 0.9027, Val Accuracy: 59.40%\n",
      "Epoch [52/250], Train Loss: 0.9122, Train Accuracy: 61.20%, Val Loss: 0.8772, Val Accuracy: 60.26%\n",
      "Epoch [53/250], Train Loss: 0.8608, Train Accuracy: 64.11%, Val Loss: 0.9342, Val Accuracy: 55.56%\n",
      "Epoch [54/250], Train Loss: 0.8752, Train Accuracy: 63.54%, Val Loss: 0.9654, Val Accuracy: 59.40%\n",
      "Epoch [55/250], Train Loss: 0.8763, Train Accuracy: 63.11%, Val Loss: 0.9359, Val Accuracy: 55.56%\n",
      "Epoch [56/250], Train Loss: 0.8658, Train Accuracy: 63.78%, Val Loss: 0.9737, Val Accuracy: 59.40%\n",
      "Epoch [57/250], Train Loss: 0.8603, Train Accuracy: 62.92%, Val Loss: 1.0517, Val Accuracy: 54.27%\n",
      "Epoch [58/250], Train Loss: 0.8621, Train Accuracy: 62.87%, Val Loss: 0.8879, Val Accuracy: 58.55%\n",
      "Epoch [59/250], Train Loss: 0.8474, Train Accuracy: 63.63%, Val Loss: 0.9504, Val Accuracy: 56.41%\n",
      "Epoch [60/250], Train Loss: 0.8600, Train Accuracy: 63.63%, Val Loss: 0.8822, Val Accuracy: 59.40%\n",
      "Epoch [61/250], Train Loss: 0.8378, Train Accuracy: 63.63%, Val Loss: 1.0075, Val Accuracy: 55.56%\n",
      "Epoch [62/250], Train Loss: 0.8393, Train Accuracy: 64.73%, Val Loss: 0.9351, Val Accuracy: 58.97%\n",
      "Epoch [63/250], Train Loss: 0.8075, Train Accuracy: 66.68%, Val Loss: 0.8456, Val Accuracy: 64.10%\n",
      "Epoch [64/250], Train Loss: 0.8271, Train Accuracy: 65.87%, Val Loss: 0.9088, Val Accuracy: 57.26%\n",
      "Epoch [65/250], Train Loss: 0.7965, Train Accuracy: 66.97%, Val Loss: 0.8831, Val Accuracy: 63.25%\n",
      "Epoch [66/250], Train Loss: 0.8305, Train Accuracy: 65.11%, Val Loss: 0.8988, Val Accuracy: 60.26%\n",
      "Epoch [67/250], Train Loss: 0.8329, Train Accuracy: 64.59%, Val Loss: 1.0807, Val Accuracy: 56.84%\n",
      "Epoch [68/250], Train Loss: 0.8127, Train Accuracy: 67.16%, Val Loss: 0.8931, Val Accuracy: 58.97%\n",
      "Epoch [69/250], Train Loss: 0.7987, Train Accuracy: 66.73%, Val Loss: 0.9768, Val Accuracy: 55.98%\n",
      "Epoch [70/250], Train Loss: 0.7912, Train Accuracy: 67.02%, Val Loss: 0.8737, Val Accuracy: 60.26%\n",
      "Epoch [71/250], Train Loss: 0.7841, Train Accuracy: 67.83%, Val Loss: 0.9504, Val Accuracy: 55.56%\n",
      "Epoch [72/250], Train Loss: 0.7892, Train Accuracy: 68.26%, Val Loss: 0.9213, Val Accuracy: 58.12%\n",
      "Epoch [73/250], Train Loss: 0.7925, Train Accuracy: 66.83%, Val Loss: 0.8867, Val Accuracy: 60.26%\n",
      "Epoch [74/250], Train Loss: 0.7505, Train Accuracy: 69.40%, Val Loss: 0.9599, Val Accuracy: 57.69%\n",
      "Epoch [75/250], Train Loss: 0.7711, Train Accuracy: 68.30%, Val Loss: 0.8928, Val Accuracy: 61.11%\n",
      "Epoch [76/250], Train Loss: 0.7640, Train Accuracy: 67.97%, Val Loss: 0.9076, Val Accuracy: 61.54%\n",
      "Epoch [77/250], Train Loss: 0.7810, Train Accuracy: 67.83%, Val Loss: 0.8236, Val Accuracy: 64.10%\n",
      "Epoch [78/250], Train Loss: 0.7456, Train Accuracy: 67.97%, Val Loss: 0.9181, Val Accuracy: 57.26%\n",
      "Epoch [79/250], Train Loss: 0.7614, Train Accuracy: 69.11%, Val Loss: 0.9095, Val Accuracy: 59.83%\n",
      "Epoch [80/250], Train Loss: 0.7392, Train Accuracy: 69.07%, Val Loss: 0.9246, Val Accuracy: 58.55%\n",
      "Epoch [81/250], Train Loss: 0.7449, Train Accuracy: 70.16%, Val Loss: 0.8919, Val Accuracy: 62.39%\n",
      "Epoch [82/250], Train Loss: 0.7159, Train Accuracy: 70.26%, Val Loss: 0.8943, Val Accuracy: 60.26%\n",
      "Epoch [83/250], Train Loss: 0.7471, Train Accuracy: 68.54%, Val Loss: 0.8881, Val Accuracy: 61.54%\n",
      "Epoch [84/250], Train Loss: 0.7176, Train Accuracy: 70.54%, Val Loss: 0.8965, Val Accuracy: 57.69%\n",
      "Epoch [85/250], Train Loss: 0.7152, Train Accuracy: 70.73%, Val Loss: 0.8616, Val Accuracy: 62.39%\n",
      "Epoch [86/250], Train Loss: 0.7150, Train Accuracy: 70.92%, Val Loss: 0.8651, Val Accuracy: 63.68%\n",
      "Epoch [87/250], Train Loss: 0.6983, Train Accuracy: 71.16%, Val Loss: 0.8998, Val Accuracy: 63.68%\n",
      "Epoch [88/250], Train Loss: 0.7355, Train Accuracy: 69.83%, Val Loss: 0.8571, Val Accuracy: 63.25%\n",
      "Epoch [89/250], Train Loss: 0.7118, Train Accuracy: 70.73%, Val Loss: 0.8519, Val Accuracy: 64.10%\n",
      "Epoch [90/250], Train Loss: 0.7072, Train Accuracy: 71.40%, Val Loss: 0.8701, Val Accuracy: 64.53%\n",
      "Epoch [91/250], Train Loss: 0.7171, Train Accuracy: 69.16%, Val Loss: 0.9399, Val Accuracy: 60.26%\n",
      "Epoch [92/250], Train Loss: 0.7309, Train Accuracy: 69.88%, Val Loss: 0.8371, Val Accuracy: 62.82%\n",
      "Epoch [93/250], Train Loss: 0.7260, Train Accuracy: 69.64%, Val Loss: 0.9037, Val Accuracy: 59.40%\n",
      "Epoch [94/250], Train Loss: 0.6942, Train Accuracy: 71.73%, Val Loss: 0.9313, Val Accuracy: 61.54%\n",
      "Epoch [95/250], Train Loss: 0.6826, Train Accuracy: 71.97%, Val Loss: 0.8845, Val Accuracy: 61.54%\n",
      "Epoch [96/250], Train Loss: 0.6783, Train Accuracy: 73.50%, Val Loss: 0.9262, Val Accuracy: 60.26%\n",
      "Epoch [97/250], Train Loss: 0.6895, Train Accuracy: 72.26%, Val Loss: 0.8672, Val Accuracy: 64.53%\n",
      "Epoch [98/250], Train Loss: 0.6944, Train Accuracy: 72.31%, Val Loss: 0.9693, Val Accuracy: 58.97%\n",
      "Epoch [99/250], Train Loss: 0.6957, Train Accuracy: 71.73%, Val Loss: 0.8846, Val Accuracy: 64.10%\n",
      "Epoch [100/250], Train Loss: 0.6578, Train Accuracy: 73.93%, Val Loss: 0.8484, Val Accuracy: 63.68%\n",
      "Epoch [101/250], Train Loss: 0.6397, Train Accuracy: 74.79%, Val Loss: 0.9166, Val Accuracy: 61.54%\n",
      "Epoch [102/250], Train Loss: 0.6402, Train Accuracy: 73.98%, Val Loss: 0.8159, Val Accuracy: 68.38%\n",
      "Epoch [103/250], Train Loss: 0.6495, Train Accuracy: 74.26%, Val Loss: 0.8598, Val Accuracy: 63.25%\n",
      "Epoch [104/250], Train Loss: 0.6513, Train Accuracy: 73.26%, Val Loss: 0.8477, Val Accuracy: 64.10%\n",
      "Epoch [105/250], Train Loss: 0.6462, Train Accuracy: 74.59%, Val Loss: 0.9634, Val Accuracy: 61.97%\n",
      "Epoch [106/250], Train Loss: 0.6482, Train Accuracy: 74.36%, Val Loss: 0.9412, Val Accuracy: 63.25%\n",
      "Epoch [107/250], Train Loss: 0.6391, Train Accuracy: 74.69%, Val Loss: 0.8733, Val Accuracy: 64.53%\n",
      "Epoch [108/250], Train Loss: 0.6169, Train Accuracy: 75.74%, Val Loss: 0.9368, Val Accuracy: 63.68%\n",
      "Epoch [109/250], Train Loss: 0.6218, Train Accuracy: 75.60%, Val Loss: 0.8506, Val Accuracy: 64.10%\n",
      "Epoch [110/250], Train Loss: 0.6252, Train Accuracy: 75.83%, Val Loss: 0.7937, Val Accuracy: 67.95%\n",
      "Epoch [111/250], Train Loss: 0.6360, Train Accuracy: 74.50%, Val Loss: 0.8334, Val Accuracy: 64.53%\n",
      "Epoch [112/250], Train Loss: 0.6414, Train Accuracy: 75.83%, Val Loss: 0.9583, Val Accuracy: 62.82%\n",
      "Epoch [113/250], Train Loss: 0.6703, Train Accuracy: 73.07%, Val Loss: 0.8102, Val Accuracy: 65.38%\n",
      "Epoch [114/250], Train Loss: 0.6307, Train Accuracy: 74.55%, Val Loss: 0.9094, Val Accuracy: 64.10%\n",
      "Epoch [115/250], Train Loss: 0.6458, Train Accuracy: 74.50%, Val Loss: 0.8423, Val Accuracy: 66.67%\n",
      "Epoch [116/250], Train Loss: 0.6163, Train Accuracy: 75.74%, Val Loss: 0.9715, Val Accuracy: 61.97%\n",
      "Epoch [117/250], Train Loss: 0.6225, Train Accuracy: 75.21%, Val Loss: 0.8490, Val Accuracy: 68.38%\n",
      "Epoch [118/250], Train Loss: 0.5948, Train Accuracy: 75.74%, Val Loss: 0.8369, Val Accuracy: 64.53%\n",
      "Epoch [119/250], Train Loss: 0.6091, Train Accuracy: 76.36%, Val Loss: 0.8073, Val Accuracy: 65.38%\n",
      "Epoch [120/250], Train Loss: 0.6052, Train Accuracy: 75.31%, Val Loss: 0.7633, Val Accuracy: 68.38%\n",
      "Epoch [121/250], Train Loss: 0.5996, Train Accuracy: 75.74%, Val Loss: 0.9220, Val Accuracy: 63.68%\n",
      "Epoch [122/250], Train Loss: 0.6066, Train Accuracy: 76.07%, Val Loss: 0.8526, Val Accuracy: 65.81%\n",
      "Epoch [123/250], Train Loss: 0.5932, Train Accuracy: 76.22%, Val Loss: 0.8833, Val Accuracy: 64.53%\n",
      "Epoch [124/250], Train Loss: 0.6171, Train Accuracy: 75.31%, Val Loss: 0.8348, Val Accuracy: 64.10%\n",
      "Epoch [125/250], Train Loss: 0.6056, Train Accuracy: 75.69%, Val Loss: 0.8433, Val Accuracy: 63.25%\n",
      "Epoch [126/250], Train Loss: 0.5839, Train Accuracy: 77.03%, Val Loss: 0.8497, Val Accuracy: 66.67%\n",
      "Epoch [127/250], Train Loss: 0.5990, Train Accuracy: 76.12%, Val Loss: 0.8132, Val Accuracy: 67.95%\n",
      "Epoch [128/250], Train Loss: 0.5977, Train Accuracy: 76.50%, Val Loss: 0.7919, Val Accuracy: 65.38%\n",
      "Epoch [129/250], Train Loss: 0.6018, Train Accuracy: 77.22%, Val Loss: 0.8065, Val Accuracy: 66.67%\n",
      "Epoch [130/250], Train Loss: 0.5701, Train Accuracy: 77.60%, Val Loss: 0.8152, Val Accuracy: 67.95%\n",
      "Epoch [131/250], Train Loss: 0.5610, Train Accuracy: 78.07%, Val Loss: 0.9014, Val Accuracy: 64.53%\n",
      "Epoch [132/250], Train Loss: 0.5502, Train Accuracy: 79.03%, Val Loss: 0.8757, Val Accuracy: 65.81%\n",
      "Epoch [133/250], Train Loss: 0.5552, Train Accuracy: 78.27%, Val Loss: 1.0149, Val Accuracy: 61.54%\n",
      "Epoch [134/250], Train Loss: 0.5714, Train Accuracy: 78.41%, Val Loss: 0.8621, Val Accuracy: 63.68%\n",
      "Epoch [135/250], Train Loss: 0.5607, Train Accuracy: 77.07%, Val Loss: 0.9030, Val Accuracy: 63.68%\n",
      "Epoch [136/250], Train Loss: 0.5290, Train Accuracy: 79.60%, Val Loss: 0.8853, Val Accuracy: 66.24%\n",
      "Epoch [137/250], Train Loss: 0.5590, Train Accuracy: 78.17%, Val Loss: 0.8054, Val Accuracy: 69.66%\n",
      "Epoch [138/250], Train Loss: 0.5909, Train Accuracy: 77.69%, Val Loss: 1.0182, Val Accuracy: 59.83%\n",
      "Epoch [139/250], Train Loss: 0.6108, Train Accuracy: 76.17%, Val Loss: 0.7818, Val Accuracy: 66.67%\n",
      "Epoch [140/250], Train Loss: 0.5539, Train Accuracy: 78.12%, Val Loss: 0.7867, Val Accuracy: 67.09%\n",
      "Epoch [141/250], Train Loss: 0.5504, Train Accuracy: 78.27%, Val Loss: 0.9887, Val Accuracy: 62.39%\n",
      "Epoch [142/250], Train Loss: 0.6096, Train Accuracy: 76.17%, Val Loss: 0.8505, Val Accuracy: 63.68%\n",
      "Epoch [143/250], Train Loss: 0.5463, Train Accuracy: 77.98%, Val Loss: 0.8443, Val Accuracy: 66.24%\n",
      "Epoch [144/250], Train Loss: 0.5471, Train Accuracy: 78.88%, Val Loss: 0.8833, Val Accuracy: 64.10%\n",
      "Epoch [145/250], Train Loss: 0.5321, Train Accuracy: 78.74%, Val Loss: 0.9014, Val Accuracy: 66.24%\n",
      "Epoch [146/250], Train Loss: 0.5539, Train Accuracy: 78.60%, Val Loss: 0.8718, Val Accuracy: 64.53%\n",
      "Epoch [147/250], Train Loss: 0.5496, Train Accuracy: 79.41%, Val Loss: 0.8638, Val Accuracy: 66.24%\n",
      "Epoch [148/250], Train Loss: 0.5423, Train Accuracy: 78.65%, Val Loss: 0.9672, Val Accuracy: 64.53%\n",
      "Epoch [149/250], Train Loss: 0.5430, Train Accuracy: 78.31%, Val Loss: 0.8308, Val Accuracy: 66.24%\n",
      "Epoch [150/250], Train Loss: 0.5338, Train Accuracy: 79.93%, Val Loss: 0.8344, Val Accuracy: 67.95%\n",
      "Epoch [151/250], Train Loss: 0.4950, Train Accuracy: 81.03%, Val Loss: 0.8596, Val Accuracy: 66.67%\n",
      "Epoch [152/250], Train Loss: 0.5358, Train Accuracy: 79.50%, Val Loss: 0.7589, Val Accuracy: 70.09%\n",
      "Epoch [153/250], Train Loss: 0.5373, Train Accuracy: 78.84%, Val Loss: 0.7805, Val Accuracy: 67.52%\n",
      "Epoch [154/250], Train Loss: 0.5196, Train Accuracy: 79.79%, Val Loss: 0.8569, Val Accuracy: 68.80%\n",
      "Epoch [155/250], Train Loss: 0.5267, Train Accuracy: 79.03%, Val Loss: 0.8678, Val Accuracy: 66.24%\n",
      "Epoch [156/250], Train Loss: 0.5229, Train Accuracy: 80.12%, Val Loss: 0.8328, Val Accuracy: 66.67%\n",
      "Epoch [157/250], Train Loss: 0.5105, Train Accuracy: 80.03%, Val Loss: 0.8505, Val Accuracy: 67.09%\n",
      "Epoch [158/250], Train Loss: 0.4841, Train Accuracy: 81.46%, Val Loss: 0.8223, Val Accuracy: 65.81%\n",
      "Epoch [159/250], Train Loss: 0.5253, Train Accuracy: 80.36%, Val Loss: 0.7955, Val Accuracy: 69.66%\n",
      "Epoch [160/250], Train Loss: 0.5062, Train Accuracy: 81.12%, Val Loss: 0.8666, Val Accuracy: 67.09%\n",
      "Epoch [161/250], Train Loss: 0.4956, Train Accuracy: 80.36%, Val Loss: 1.1181, Val Accuracy: 57.69%\n",
      "Epoch [162/250], Train Loss: 0.5240, Train Accuracy: 79.55%, Val Loss: 0.8596, Val Accuracy: 69.66%\n",
      "Epoch [163/250], Train Loss: 0.5089, Train Accuracy: 80.84%, Val Loss: 0.8511, Val Accuracy: 68.38%\n",
      "Epoch [164/250], Train Loss: 0.5029, Train Accuracy: 81.03%, Val Loss: 0.7606, Val Accuracy: 66.67%\n",
      "Epoch [165/250], Train Loss: 0.4816, Train Accuracy: 80.89%, Val Loss: 0.7415, Val Accuracy: 66.67%\n",
      "Epoch [166/250], Train Loss: 0.4696, Train Accuracy: 82.55%, Val Loss: 0.8843, Val Accuracy: 68.38%\n",
      "Epoch [167/250], Train Loss: 0.5495, Train Accuracy: 78.31%, Val Loss: 0.8667, Val Accuracy: 69.23%\n",
      "Epoch [168/250], Train Loss: 0.4839, Train Accuracy: 81.36%, Val Loss: 0.8074, Val Accuracy: 70.94%\n",
      "Epoch [169/250], Train Loss: 0.4907, Train Accuracy: 81.70%, Val Loss: 0.9657, Val Accuracy: 64.10%\n",
      "Epoch [170/250], Train Loss: 0.5021, Train Accuracy: 80.74%, Val Loss: 0.8767, Val Accuracy: 67.09%\n",
      "Epoch [171/250], Train Loss: 0.4998, Train Accuracy: 80.46%, Val Loss: 0.7796, Val Accuracy: 68.38%\n",
      "Epoch [172/250], Train Loss: 0.4929, Train Accuracy: 81.55%, Val Loss: 0.8954, Val Accuracy: 68.38%\n",
      "Epoch [173/250], Train Loss: 0.5250, Train Accuracy: 79.27%, Val Loss: 0.8897, Val Accuracy: 63.25%\n",
      "Epoch [174/250], Train Loss: 0.5347, Train Accuracy: 79.69%, Val Loss: 0.9130, Val Accuracy: 63.25%\n",
      "Epoch [175/250], Train Loss: 0.5135, Train Accuracy: 79.31%, Val Loss: 0.7884, Val Accuracy: 69.23%\n",
      "Epoch [176/250], Train Loss: 0.4622, Train Accuracy: 82.60%, Val Loss: 0.8664, Val Accuracy: 68.80%\n",
      "Epoch [177/250], Train Loss: 0.4787, Train Accuracy: 80.89%, Val Loss: 0.8745, Val Accuracy: 63.68%\n",
      "Epoch [178/250], Train Loss: 0.4917, Train Accuracy: 81.89%, Val Loss: 0.8828, Val Accuracy: 64.53%\n",
      "Epoch [179/250], Train Loss: 0.4795, Train Accuracy: 81.79%, Val Loss: 0.8012, Val Accuracy: 69.23%\n",
      "Epoch [180/250], Train Loss: 0.4728, Train Accuracy: 81.41%, Val Loss: 0.8167, Val Accuracy: 69.66%\n",
      "Epoch [181/250], Train Loss: 0.5279, Train Accuracy: 80.12%, Val Loss: 0.7334, Val Accuracy: 68.38%\n",
      "Epoch [182/250], Train Loss: 0.4481, Train Accuracy: 83.13%, Val Loss: 0.8254, Val Accuracy: 64.10%\n",
      "Epoch [183/250], Train Loss: 0.4602, Train Accuracy: 82.55%, Val Loss: 0.8961, Val Accuracy: 62.39%\n",
      "Epoch [184/250], Train Loss: 0.4775, Train Accuracy: 81.79%, Val Loss: 0.8480, Val Accuracy: 66.67%\n",
      "Epoch [185/250], Train Loss: 0.5214, Train Accuracy: 80.08%, Val Loss: 0.8926, Val Accuracy: 64.96%\n",
      "Epoch [186/250], Train Loss: 0.4442, Train Accuracy: 82.46%, Val Loss: 0.7913, Val Accuracy: 70.09%\n",
      "Epoch [187/250], Train Loss: 0.4648, Train Accuracy: 82.55%, Val Loss: 0.7854, Val Accuracy: 70.94%\n",
      "Epoch [188/250], Train Loss: 0.4610, Train Accuracy: 82.94%, Val Loss: 0.8942, Val Accuracy: 64.53%\n",
      "Epoch [189/250], Train Loss: 0.5145, Train Accuracy: 80.36%, Val Loss: 0.8906, Val Accuracy: 67.95%\n",
      "Epoch [190/250], Train Loss: 0.4683, Train Accuracy: 81.70%, Val Loss: 1.0540, Val Accuracy: 65.38%\n",
      "Epoch [191/250], Train Loss: 0.4796, Train Accuracy: 81.27%, Val Loss: 0.8128, Val Accuracy: 71.37%\n",
      "Epoch [192/250], Train Loss: 0.4883, Train Accuracy: 81.94%, Val Loss: 0.8188, Val Accuracy: 69.23%\n",
      "Epoch [193/250], Train Loss: 0.4732, Train Accuracy: 82.08%, Val Loss: 0.8424, Val Accuracy: 66.67%\n",
      "Epoch [194/250], Train Loss: 0.4695, Train Accuracy: 81.74%, Val Loss: 0.8488, Val Accuracy: 67.95%\n",
      "Epoch [195/250], Train Loss: 0.4817, Train Accuracy: 81.65%, Val Loss: 0.8730, Val Accuracy: 66.24%\n",
      "Epoch [196/250], Train Loss: 0.4363, Train Accuracy: 83.51%, Val Loss: 0.7611, Val Accuracy: 70.94%\n",
      "Epoch [197/250], Train Loss: 0.4519, Train Accuracy: 81.94%, Val Loss: 0.8021, Val Accuracy: 70.09%\n",
      "Epoch [198/250], Train Loss: 0.4345, Train Accuracy: 83.17%, Val Loss: 0.8898, Val Accuracy: 69.23%\n",
      "Epoch [199/250], Train Loss: 0.4736, Train Accuracy: 82.27%, Val Loss: 0.8843, Val Accuracy: 67.52%\n",
      "Epoch [200/250], Train Loss: 0.4439, Train Accuracy: 83.08%, Val Loss: 0.8645, Val Accuracy: 66.67%\n",
      "Epoch [201/250], Train Loss: 0.4441, Train Accuracy: 82.98%, Val Loss: 0.8310, Val Accuracy: 67.09%\n",
      "Epoch [202/250], Train Loss: 0.4226, Train Accuracy: 83.98%, Val Loss: 0.9027, Val Accuracy: 67.52%\n",
      "Epoch [203/250], Train Loss: 0.4522, Train Accuracy: 81.74%, Val Loss: 0.9188, Val Accuracy: 65.38%\n",
      "Epoch [204/250], Train Loss: 0.4425, Train Accuracy: 83.32%, Val Loss: 0.7799, Val Accuracy: 69.23%\n",
      "Epoch [205/250], Train Loss: 0.4334, Train Accuracy: 83.13%, Val Loss: 0.8211, Val Accuracy: 67.52%\n",
      "Epoch [206/250], Train Loss: 0.4550, Train Accuracy: 82.75%, Val Loss: 0.9970, Val Accuracy: 64.96%\n",
      "Epoch [207/250], Train Loss: 0.4481, Train Accuracy: 82.84%, Val Loss: 0.8709, Val Accuracy: 64.10%\n",
      "Epoch [208/250], Train Loss: 0.4459, Train Accuracy: 82.84%, Val Loss: 0.9002, Val Accuracy: 62.39%\n",
      "Epoch [209/250], Train Loss: 0.4645, Train Accuracy: 82.03%, Val Loss: 0.9841, Val Accuracy: 63.68%\n",
      "Epoch [210/250], Train Loss: 0.4175, Train Accuracy: 84.32%, Val Loss: 0.8173, Val Accuracy: 67.95%\n",
      "Epoch [211/250], Train Loss: 0.3996, Train Accuracy: 85.37%, Val Loss: 0.7627, Val Accuracy: 69.66%\n",
      "Epoch [212/250], Train Loss: 0.4514, Train Accuracy: 82.70%, Val Loss: 1.0608, Val Accuracy: 61.97%\n",
      "Epoch [213/250], Train Loss: 0.4500, Train Accuracy: 83.75%, Val Loss: 0.8249, Val Accuracy: 70.09%\n",
      "Epoch [214/250], Train Loss: 0.4508, Train Accuracy: 83.03%, Val Loss: 0.8363, Val Accuracy: 69.66%\n",
      "Epoch [215/250], Train Loss: 0.3982, Train Accuracy: 85.37%, Val Loss: 0.8924, Val Accuracy: 67.09%\n",
      "Epoch [216/250], Train Loss: 0.4426, Train Accuracy: 82.94%, Val Loss: 0.8732, Val Accuracy: 64.53%\n",
      "Epoch [217/250], Train Loss: 0.4205, Train Accuracy: 84.22%, Val Loss: 0.7774, Val Accuracy: 67.09%\n",
      "Epoch [218/250], Train Loss: 0.4239, Train Accuracy: 83.70%, Val Loss: 0.8184, Val Accuracy: 68.38%\n",
      "Epoch [219/250], Train Loss: 0.4340, Train Accuracy: 84.18%, Val Loss: 0.7991, Val Accuracy: 68.80%\n",
      "Epoch [220/250], Train Loss: 0.4596, Train Accuracy: 81.79%, Val Loss: 0.7933, Val Accuracy: 68.80%\n",
      "Epoch [221/250], Train Loss: 0.4167, Train Accuracy: 84.75%, Val Loss: 0.9019, Val Accuracy: 64.96%\n",
      "Epoch [222/250], Train Loss: 0.4305, Train Accuracy: 83.89%, Val Loss: 0.7127, Val Accuracy: 70.09%\n",
      "Epoch [223/250], Train Loss: 0.3821, Train Accuracy: 85.18%, Val Loss: 0.9454, Val Accuracy: 65.81%\n",
      "Epoch [224/250], Train Loss: 0.4205, Train Accuracy: 84.08%, Val Loss: 0.8201, Val Accuracy: 69.66%\n",
      "Epoch [225/250], Train Loss: 0.4279, Train Accuracy: 83.03%, Val Loss: 0.8178, Val Accuracy: 68.80%\n",
      "Epoch [226/250], Train Loss: 0.4393, Train Accuracy: 83.41%, Val Loss: 0.8110, Val Accuracy: 70.09%\n",
      "Epoch [227/250], Train Loss: 0.4264, Train Accuracy: 83.46%, Val Loss: 1.1830, Val Accuracy: 61.11%\n",
      "Epoch [228/250], Train Loss: 0.4548, Train Accuracy: 83.32%, Val Loss: 0.9931, Val Accuracy: 64.53%\n",
      "Epoch [229/250], Train Loss: 0.4161, Train Accuracy: 84.94%, Val Loss: 0.7826, Val Accuracy: 70.51%\n",
      "Epoch [230/250], Train Loss: 0.4284, Train Accuracy: 83.03%, Val Loss: 0.8427, Val Accuracy: 66.24%\n",
      "Epoch [231/250], Train Loss: 0.4252, Train Accuracy: 83.75%, Val Loss: 0.8298, Val Accuracy: 67.52%\n",
      "Epoch [232/250], Train Loss: 0.3954, Train Accuracy: 85.03%, Val Loss: 0.8049, Val Accuracy: 67.09%\n",
      "Epoch [233/250], Train Loss: 0.4124, Train Accuracy: 84.46%, Val Loss: 0.8070, Val Accuracy: 67.95%\n",
      "Epoch [234/250], Train Loss: 0.4144, Train Accuracy: 83.94%, Val Loss: 0.9068, Val Accuracy: 67.52%\n",
      "Epoch [235/250], Train Loss: 0.4121, Train Accuracy: 84.08%, Val Loss: 0.8337, Val Accuracy: 65.81%\n",
      "Epoch [236/250], Train Loss: 0.4235, Train Accuracy: 83.46%, Val Loss: 0.8554, Val Accuracy: 67.52%\n",
      "Epoch [237/250], Train Loss: 0.4157, Train Accuracy: 83.46%, Val Loss: 0.9818, Val Accuracy: 63.25%\n",
      "Epoch [238/250], Train Loss: 0.4074, Train Accuracy: 83.89%, Val Loss: 0.9061, Val Accuracy: 67.09%\n",
      "Epoch [239/250], Train Loss: 0.4241, Train Accuracy: 83.79%, Val Loss: 0.8735, Val Accuracy: 68.38%\n",
      "Epoch [240/250], Train Loss: 0.4042, Train Accuracy: 84.65%, Val Loss: 0.9508, Val Accuracy: 65.38%\n",
      "Epoch [241/250], Train Loss: 0.3912, Train Accuracy: 86.13%, Val Loss: 0.8572, Val Accuracy: 66.24%\n",
      "Epoch [242/250], Train Loss: 0.4022, Train Accuracy: 83.84%, Val Loss: 1.0082, Val Accuracy: 64.96%\n",
      "Epoch [243/250], Train Loss: 0.4228, Train Accuracy: 83.89%, Val Loss: 0.9200, Val Accuracy: 64.10%\n",
      "Epoch [244/250], Train Loss: 0.4395, Train Accuracy: 84.51%, Val Loss: 0.8155, Val Accuracy: 67.52%\n",
      "Epoch [245/250], Train Loss: 0.4064, Train Accuracy: 85.18%, Val Loss: 0.8475, Val Accuracy: 68.38%\n",
      "Epoch [246/250], Train Loss: 0.4081, Train Accuracy: 84.65%, Val Loss: 0.7988, Val Accuracy: 66.67%\n",
      "Epoch [247/250], Train Loss: 0.3971, Train Accuracy: 84.75%, Val Loss: 0.8311, Val Accuracy: 67.09%\n",
      "Epoch [248/250], Train Loss: 0.3758, Train Accuracy: 85.89%, Val Loss: 0.8812, Val Accuracy: 67.52%\n",
      "Epoch [249/250], Train Loss: 0.4024, Train Accuracy: 84.51%, Val Loss: 0.8156, Val Accuracy: 70.51%\n",
      "Epoch [250/250], Train Loss: 0.3936, Train Accuracy: 85.03%, Val Loss: 0.8100, Val Accuracy: 66.24%\n",
      "Final accuracy on test set: 68.85%\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        \n",
    "        #First CNN Layer\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, output_channel, padding=0, kernel_size=20, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #First LSTM layers with bidirectional\n",
    "        self.lstm1 = nn.LSTM(output_channel, hidden_size=lstm_hidden_dim1, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        #Second CNN Layer\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(lstm_hidden_dim1*2, output_channel2, padding=0, kernel_size=10, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel2),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #Second Lstm layer with bidirectional\n",
    "        self.lstm2 = nn.LSTM(output_channel2, lstm_hidden_dim2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(lstm_hidden_dim2 * 2 * 3, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.cnn(x)  # Apply CNN\n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM (batch_size, seq_len, num_features)\n",
    "        \n",
    "        x, _ = self.lstm1(x)  # First LSTM layer\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute back for CNN\n",
    "        x = self.cnn2(x)  # Apply second CNN layer\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM\n",
    "        \n",
    "        x, _ = self.lstm2(x) # Second LSTM layer\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.contiguous().view(x.size(0), -1)  # Flatten for FC layer\n",
    "        x = self.fc(x)  # Apply fully connected layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_normal_(param)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.zeros_(param)\n",
    "                        n = param.size(0)\n",
    "                        param[n // 4:n // 2].data.fill_(1.0)  # Set forget gate bias to 1.0\n",
    "\n",
    "input_channels = 22  \n",
    "output_channel = 40\n",
    "output_channel2 = 30\n",
    "lstm_hidden_dim1 = 70\n",
    "lstm_hidden_dim2 = 50\n",
    "num_classes = 4  \n",
    "\n",
    "# Instantiate the model\n",
    "model = CNNLSTM(input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007, weight_decay=.002)\n",
    "# Training the model\n",
    "num_epochs = 250\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "# Testing Phase\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\t\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final accuracy on test set: {final_accuracy:.2f}%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
