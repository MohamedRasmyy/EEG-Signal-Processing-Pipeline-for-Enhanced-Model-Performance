{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the preprocessed data\n",
    "X = np.load('X_all_No_ASR.npy')\n",
    "Y = np.load('Y_all_No_ASR.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (2098, 22, 1126)\n",
      "Validation set shape: (234, 22, 1126)\n",
      "Test set shape: (260, 22, 1126)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=.1,random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed)  # Split train into train (85%) and validation (15%)\n",
    "\n",
    "X_train_flatten = X_train.reshape(-1, X_train.shape[-1])  # Shape: (num_train_epochs * num_channels, seq_len)\n",
    "X_val_flatten = X_val.reshape(-1, X_val.shape[-1])        # Validation set\n",
    "X_test_flatten = X_test.reshape(-1, X_test.shape[-1])  # Shape: (num_test_epochs * num_channels, seq_len)\n",
    "\n",
    "mean = X_train_flatten.mean(axis=0)  # Compute the mean for each feature\n",
    "X_train_centered = X_train_flatten - mean\n",
    "X_val_centered = X_val_flatten - mean  # Center validation data using train set mean\n",
    "X_test_centered = X_test_flatten - mean  # Apply the same mean to X_test\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # Disable mean subtraction since we already did it\n",
    "X_train_scaled = scaler.fit_transform(X_train_centered)  # Fit on X_train\n",
    "X_val_scaled = scaler.transform(X_val_centered)  # Apply the same scaler to validation data\n",
    "X_test_scaled = scaler.transform(X_test_centered)  # Transform X_test using the same scaler\n",
    "\n",
    "X_train_final = X_train_scaled.reshape(X_train.shape)  # Shape: (num_train_epochs, num_channels, seq_len)\n",
    "X_val_final = X_val_scaled.reshape(X_val.shape)        # Shape: (num_val_epochs, num_channels, seq_len)\n",
    "X_test_final = X_test_scaled.reshape(X_test.shape)  # Shape: (num_test_epochs, num_channels, seq_len)\n",
    "\n",
    "print(\"Train set shape:\", X_train_final.shape)\n",
    "print(\"Validation set shape:\", X_val_final.shape)\n",
    "print(\"Test set shape:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert Numpy Arrays to PyTorch Tensors\n",
    "X_train1=torch.tensor(X_train_final,dtype=torch.float32)\n",
    "X_val1=torch.tensor(X_val_final,dtype=torch.float32)\n",
    "X_test1=torch.tensor(X_test_final,dtype=torch.float32)\n",
    "\n",
    "y_train1=torch.tensor(y_train,dtype=torch.long)\n",
    "y_val1=torch.tensor(y_val,dtype=torch.long)\n",
    "y_test1=torch.tensor(y_test,dtype=torch.long)\n",
    "\n",
    "# 2. Create TensorDatasets for Train, Validation, and Test Sets\n",
    "train_dataset=TensorDataset(X_train1,y_train1)\n",
    "val_dataset=TensorDataset(X_val1,y_val1)\n",
    "test_dataset=TensorDataset(X_test1,y_test1)\n",
    "\n",
    "# 3. Create DataLoaders for Batch Processing\n",
    "train_loader=DataLoader(train_dataset,batch_size=100,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=100,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Train Loss: 1.4431, Train Accuracy: 25.12%, Val Loss: 1.3695, Val Accuracy: 33.33%\n",
      "Epoch [2/250], Train Loss: 1.4355, Train Accuracy: 24.26%, Val Loss: 1.3574, Val Accuracy: 33.33%\n",
      "Epoch [3/250], Train Loss: 1.4113, Train Accuracy: 26.45%, Val Loss: 1.3538, Val Accuracy: 33.33%\n",
      "Epoch [4/250], Train Loss: 1.3974, Train Accuracy: 28.98%, Val Loss: 1.3501, Val Accuracy: 31.20%\n",
      "Epoch [5/250], Train Loss: 1.3836, Train Accuracy: 29.41%, Val Loss: 1.3444, Val Accuracy: 32.48%\n",
      "Epoch [6/250], Train Loss: 1.3825, Train Accuracy: 28.65%, Val Loss: 1.3220, Val Accuracy: 36.32%\n",
      "Epoch [7/250], Train Loss: 1.3502, Train Accuracy: 31.79%, Val Loss: 1.3162, Val Accuracy: 36.75%\n",
      "Epoch [8/250], Train Loss: 1.3439, Train Accuracy: 33.79%, Val Loss: 1.3224, Val Accuracy: 38.46%\n",
      "Epoch [9/250], Train Loss: 1.3198, Train Accuracy: 36.46%, Val Loss: 1.2738, Val Accuracy: 37.18%\n",
      "Epoch [10/250], Train Loss: 1.3120, Train Accuracy: 37.08%, Val Loss: 1.2543, Val Accuracy: 43.16%\n",
      "Epoch [11/250], Train Loss: 1.2857, Train Accuracy: 37.89%, Val Loss: 1.2177, Val Accuracy: 41.45%\n",
      "Epoch [12/250], Train Loss: 1.2523, Train Accuracy: 41.85%, Val Loss: 1.2100, Val Accuracy: 42.74%\n",
      "Epoch [13/250], Train Loss: 1.2518, Train Accuracy: 41.23%, Val Loss: 1.2095, Val Accuracy: 44.02%\n",
      "Epoch [14/250], Train Loss: 1.2269, Train Accuracy: 43.33%, Val Loss: 1.2091, Val Accuracy: 45.30%\n",
      "Epoch [15/250], Train Loss: 1.2125, Train Accuracy: 43.47%, Val Loss: 1.2240, Val Accuracy: 46.15%\n",
      "Epoch [16/250], Train Loss: 1.1993, Train Accuracy: 44.80%, Val Loss: 1.2022, Val Accuracy: 43.59%\n",
      "Epoch [17/250], Train Loss: 1.1910, Train Accuracy: 45.19%, Val Loss: 1.0736, Val Accuracy: 48.72%\n",
      "Epoch [18/250], Train Loss: 1.1643, Train Accuracy: 46.09%, Val Loss: 1.1708, Val Accuracy: 44.44%\n",
      "Epoch [19/250], Train Loss: 1.1462, Train Accuracy: 48.24%, Val Loss: 1.0261, Val Accuracy: 50.43%\n",
      "Epoch [20/250], Train Loss: 1.1499, Train Accuracy: 48.81%, Val Loss: 1.0471, Val Accuracy: 52.56%\n",
      "Epoch [21/250], Train Loss: 1.1394, Train Accuracy: 48.33%, Val Loss: 1.0416, Val Accuracy: 54.70%\n",
      "Epoch [22/250], Train Loss: 1.1206, Train Accuracy: 49.76%, Val Loss: 1.1014, Val Accuracy: 45.73%\n",
      "Epoch [23/250], Train Loss: 1.1048, Train Accuracy: 50.38%, Val Loss: 1.0836, Val Accuracy: 49.57%\n",
      "Epoch [24/250], Train Loss: 1.0773, Train Accuracy: 51.53%, Val Loss: 1.1395, Val Accuracy: 45.30%\n",
      "Epoch [25/250], Train Loss: 1.0766, Train Accuracy: 50.67%, Val Loss: 1.0408, Val Accuracy: 51.71%\n",
      "Epoch [26/250], Train Loss: 1.0698, Train Accuracy: 51.76%, Val Loss: 1.0052, Val Accuracy: 56.41%\n",
      "Epoch [27/250], Train Loss: 1.0651, Train Accuracy: 53.72%, Val Loss: 1.0078, Val Accuracy: 54.27%\n",
      "Epoch [28/250], Train Loss: 1.0490, Train Accuracy: 55.05%, Val Loss: 1.0152, Val Accuracy: 55.13%\n",
      "Epoch [29/250], Train Loss: 1.0394, Train Accuracy: 54.05%, Val Loss: 1.1503, Val Accuracy: 49.15%\n",
      "Epoch [30/250], Train Loss: 1.0226, Train Accuracy: 55.53%, Val Loss: 0.9587, Val Accuracy: 53.42%\n",
      "Epoch [31/250], Train Loss: 1.0332, Train Accuracy: 54.39%, Val Loss: 0.9852, Val Accuracy: 56.41%\n",
      "Epoch [32/250], Train Loss: 1.0397, Train Accuracy: 54.67%, Val Loss: 1.0781, Val Accuracy: 51.28%\n",
      "Epoch [33/250], Train Loss: 1.0073, Train Accuracy: 56.15%, Val Loss: 0.9176, Val Accuracy: 58.55%\n",
      "Epoch [34/250], Train Loss: 1.0038, Train Accuracy: 56.01%, Val Loss: 0.9109, Val Accuracy: 59.40%\n",
      "Epoch [35/250], Train Loss: 0.9704, Train Accuracy: 58.34%, Val Loss: 0.8961, Val Accuracy: 59.40%\n",
      "Epoch [36/250], Train Loss: 0.9853, Train Accuracy: 57.24%, Val Loss: 0.9123, Val Accuracy: 59.83%\n",
      "Epoch [37/250], Train Loss: 0.9912, Train Accuracy: 57.34%, Val Loss: 0.9674, Val Accuracy: 56.84%\n",
      "Epoch [38/250], Train Loss: 0.9893, Train Accuracy: 56.91%, Val Loss: 0.9996, Val Accuracy: 56.41%\n",
      "Epoch [39/250], Train Loss: 0.9643, Train Accuracy: 58.53%, Val Loss: 0.9349, Val Accuracy: 57.69%\n",
      "Epoch [40/250], Train Loss: 0.9574, Train Accuracy: 59.53%, Val Loss: 0.9512, Val Accuracy: 55.98%\n",
      "Epoch [41/250], Train Loss: 0.9771, Train Accuracy: 58.25%, Val Loss: 0.9719, Val Accuracy: 54.27%\n",
      "Epoch [42/250], Train Loss: 0.9591, Train Accuracy: 57.91%, Val Loss: 0.9102, Val Accuracy: 56.41%\n",
      "Epoch [43/250], Train Loss: 0.9354, Train Accuracy: 61.25%, Val Loss: 0.9211, Val Accuracy: 59.83%\n",
      "Epoch [44/250], Train Loss: 0.9329, Train Accuracy: 60.25%, Val Loss: 0.9398, Val Accuracy: 59.40%\n",
      "Epoch [45/250], Train Loss: 0.9272, Train Accuracy: 60.34%, Val Loss: 0.9203, Val Accuracy: 55.13%\n",
      "Epoch [46/250], Train Loss: 0.9080, Train Accuracy: 61.06%, Val Loss: 0.9478, Val Accuracy: 55.13%\n",
      "Epoch [47/250], Train Loss: 0.9438, Train Accuracy: 59.91%, Val Loss: 1.0152, Val Accuracy: 52.99%\n",
      "Epoch [48/250], Train Loss: 0.9074, Train Accuracy: 62.39%, Val Loss: 1.0268, Val Accuracy: 58.12%\n",
      "Epoch [49/250], Train Loss: 0.9044, Train Accuracy: 63.87%, Val Loss: 0.9420, Val Accuracy: 54.27%\n",
      "Epoch [50/250], Train Loss: 0.8862, Train Accuracy: 63.68%, Val Loss: 0.9936, Val Accuracy: 53.42%\n",
      "Epoch [51/250], Train Loss: 0.9068, Train Accuracy: 60.87%, Val Loss: 0.9314, Val Accuracy: 58.12%\n",
      "Epoch [52/250], Train Loss: 0.9100, Train Accuracy: 61.39%, Val Loss: 0.9252, Val Accuracy: 57.26%\n",
      "Epoch [53/250], Train Loss: 0.8493, Train Accuracy: 65.92%, Val Loss: 0.9249, Val Accuracy: 56.41%\n",
      "Epoch [54/250], Train Loss: 0.8535, Train Accuracy: 65.59%, Val Loss: 0.9192, Val Accuracy: 57.69%\n",
      "Epoch [55/250], Train Loss: 0.8528, Train Accuracy: 64.68%, Val Loss: 0.9845, Val Accuracy: 58.12%\n",
      "Epoch [56/250], Train Loss: 0.8564, Train Accuracy: 65.40%, Val Loss: 0.8920, Val Accuracy: 60.68%\n",
      "Epoch [57/250], Train Loss: 0.8390, Train Accuracy: 65.40%, Val Loss: 1.1187, Val Accuracy: 52.99%\n",
      "Epoch [58/250], Train Loss: 0.8086, Train Accuracy: 66.44%, Val Loss: 0.9423, Val Accuracy: 58.55%\n",
      "Epoch [59/250], Train Loss: 0.8366, Train Accuracy: 67.35%, Val Loss: 0.8791, Val Accuracy: 60.68%\n",
      "Epoch [60/250], Train Loss: 0.8468, Train Accuracy: 66.30%, Val Loss: 0.8713, Val Accuracy: 57.69%\n",
      "Epoch [61/250], Train Loss: 0.8073, Train Accuracy: 66.54%, Val Loss: 0.8637, Val Accuracy: 62.39%\n",
      "Epoch [62/250], Train Loss: 0.8196, Train Accuracy: 66.78%, Val Loss: 1.0702, Val Accuracy: 56.84%\n",
      "Epoch [63/250], Train Loss: 0.8031, Train Accuracy: 67.25%, Val Loss: 0.9222, Val Accuracy: 59.83%\n",
      "Epoch [64/250], Train Loss: 0.8306, Train Accuracy: 65.40%, Val Loss: 0.9389, Val Accuracy: 57.26%\n",
      "Epoch [65/250], Train Loss: 0.7929, Train Accuracy: 68.49%, Val Loss: 0.8609, Val Accuracy: 61.11%\n",
      "Epoch [66/250], Train Loss: 0.7953, Train Accuracy: 67.64%, Val Loss: 0.9217, Val Accuracy: 60.68%\n",
      "Epoch [67/250], Train Loss: 0.7918, Train Accuracy: 67.68%, Val Loss: 0.9789, Val Accuracy: 59.83%\n",
      "Epoch [68/250], Train Loss: 0.7736, Train Accuracy: 68.59%, Val Loss: 1.0014, Val Accuracy: 58.12%\n",
      "Epoch [69/250], Train Loss: 0.7755, Train Accuracy: 68.02%, Val Loss: 0.8622, Val Accuracy: 61.11%\n",
      "Epoch [70/250], Train Loss: 0.7794, Train Accuracy: 66.73%, Val Loss: 0.8798, Val Accuracy: 61.97%\n",
      "Epoch [71/250], Train Loss: 0.7662, Train Accuracy: 69.07%, Val Loss: 0.8862, Val Accuracy: 58.97%\n",
      "Epoch [72/250], Train Loss: 0.7700, Train Accuracy: 69.45%, Val Loss: 0.8928, Val Accuracy: 59.40%\n",
      "Epoch [73/250], Train Loss: 0.7894, Train Accuracy: 68.26%, Val Loss: 1.0003, Val Accuracy: 58.12%\n",
      "Epoch [74/250], Train Loss: 0.7477, Train Accuracy: 70.16%, Val Loss: 0.9403, Val Accuracy: 60.26%\n",
      "Epoch [75/250], Train Loss: 0.7386, Train Accuracy: 70.40%, Val Loss: 0.8515, Val Accuracy: 61.54%\n",
      "Epoch [76/250], Train Loss: 0.7646, Train Accuracy: 68.68%, Val Loss: 0.8984, Val Accuracy: 60.26%\n",
      "Epoch [77/250], Train Loss: 0.7572, Train Accuracy: 69.35%, Val Loss: 1.0032, Val Accuracy: 58.55%\n",
      "Epoch [78/250], Train Loss: 0.7556, Train Accuracy: 69.69%, Val Loss: 0.8705, Val Accuracy: 64.96%\n",
      "Epoch [79/250], Train Loss: 0.7595, Train Accuracy: 69.07%, Val Loss: 0.9914, Val Accuracy: 61.11%\n",
      "Epoch [80/250], Train Loss: 0.7187, Train Accuracy: 70.78%, Val Loss: 0.8920, Val Accuracy: 61.11%\n",
      "Epoch [81/250], Train Loss: 0.7364, Train Accuracy: 71.02%, Val Loss: 0.8844, Val Accuracy: 60.68%\n",
      "Epoch [82/250], Train Loss: 0.6962, Train Accuracy: 72.26%, Val Loss: 0.8531, Val Accuracy: 61.97%\n",
      "Epoch [83/250], Train Loss: 0.7318, Train Accuracy: 71.31%, Val Loss: 0.8214, Val Accuracy: 62.82%\n",
      "Epoch [84/250], Train Loss: 0.7049, Train Accuracy: 72.26%, Val Loss: 0.8935, Val Accuracy: 64.96%\n",
      "Epoch [85/250], Train Loss: 0.7129, Train Accuracy: 71.45%, Val Loss: 0.9097, Val Accuracy: 59.40%\n",
      "Epoch [86/250], Train Loss: 0.6936, Train Accuracy: 72.21%, Val Loss: 0.8740, Val Accuracy: 65.38%\n",
      "Epoch [87/250], Train Loss: 0.6909, Train Accuracy: 73.21%, Val Loss: 0.9715, Val Accuracy: 60.68%\n",
      "Epoch [88/250], Train Loss: 0.7071, Train Accuracy: 71.45%, Val Loss: 0.9044, Val Accuracy: 60.68%\n",
      "Epoch [89/250], Train Loss: 0.7010, Train Accuracy: 72.69%, Val Loss: 0.8519, Val Accuracy: 64.10%\n",
      "Epoch [90/250], Train Loss: 0.6904, Train Accuracy: 71.83%, Val Loss: 0.9425, Val Accuracy: 59.83%\n",
      "Epoch [91/250], Train Loss: 0.6970, Train Accuracy: 71.93%, Val Loss: 0.8523, Val Accuracy: 62.82%\n",
      "Epoch [92/250], Train Loss: 0.7011, Train Accuracy: 72.26%, Val Loss: 0.8631, Val Accuracy: 64.53%\n",
      "Epoch [93/250], Train Loss: 0.6985, Train Accuracy: 72.50%, Val Loss: 0.8871, Val Accuracy: 62.39%\n",
      "Epoch [94/250], Train Loss: 0.6830, Train Accuracy: 73.12%, Val Loss: 0.9108, Val Accuracy: 64.10%\n",
      "Epoch [95/250], Train Loss: 0.6690, Train Accuracy: 73.21%, Val Loss: 0.9533, Val Accuracy: 60.68%\n",
      "Epoch [96/250], Train Loss: 0.6674, Train Accuracy: 74.83%, Val Loss: 0.8509, Val Accuracy: 63.25%\n",
      "Epoch [97/250], Train Loss: 0.6994, Train Accuracy: 72.45%, Val Loss: 0.8619, Val Accuracy: 61.11%\n",
      "Epoch [98/250], Train Loss: 0.6860, Train Accuracy: 73.02%, Val Loss: 0.8654, Val Accuracy: 61.11%\n",
      "Epoch [99/250], Train Loss: 0.6420, Train Accuracy: 75.26%, Val Loss: 0.9534, Val Accuracy: 63.25%\n",
      "Epoch [100/250], Train Loss: 0.6082, Train Accuracy: 76.55%, Val Loss: 0.8504, Val Accuracy: 66.67%\n",
      "Epoch [101/250], Train Loss: 0.6362, Train Accuracy: 74.93%, Val Loss: 0.8737, Val Accuracy: 64.10%\n",
      "Epoch [102/250], Train Loss: 0.5977, Train Accuracy: 77.22%, Val Loss: 0.9480, Val Accuracy: 63.25%\n",
      "Epoch [103/250], Train Loss: 0.6463, Train Accuracy: 74.59%, Val Loss: 0.8287, Val Accuracy: 65.38%\n",
      "Epoch [104/250], Train Loss: 0.6320, Train Accuracy: 74.02%, Val Loss: 0.8669, Val Accuracy: 63.25%\n",
      "Epoch [105/250], Train Loss: 0.6279, Train Accuracy: 74.88%, Val Loss: 0.8095, Val Accuracy: 63.25%\n",
      "Epoch [106/250], Train Loss: 0.6525, Train Accuracy: 74.31%, Val Loss: 0.9632, Val Accuracy: 63.25%\n",
      "Epoch [107/250], Train Loss: 0.6298, Train Accuracy: 76.31%, Val Loss: 0.9190, Val Accuracy: 63.25%\n",
      "Epoch [108/250], Train Loss: 0.6229, Train Accuracy: 75.98%, Val Loss: 0.9441, Val Accuracy: 64.10%\n",
      "Epoch [109/250], Train Loss: 0.6533, Train Accuracy: 73.21%, Val Loss: 0.8497, Val Accuracy: 65.38%\n",
      "Epoch [110/250], Train Loss: 0.6205, Train Accuracy: 75.21%, Val Loss: 1.0372, Val Accuracy: 63.68%\n",
      "Epoch [111/250], Train Loss: 0.6271, Train Accuracy: 76.41%, Val Loss: 0.8640, Val Accuracy: 66.24%\n",
      "Epoch [112/250], Train Loss: 0.5996, Train Accuracy: 76.84%, Val Loss: 0.8191, Val Accuracy: 68.80%\n",
      "Epoch [113/250], Train Loss: 0.6228, Train Accuracy: 76.36%, Val Loss: 0.8933, Val Accuracy: 62.82%\n",
      "Epoch [114/250], Train Loss: 0.6015, Train Accuracy: 76.69%, Val Loss: 0.9075, Val Accuracy: 61.54%\n",
      "Epoch [115/250], Train Loss: 0.6085, Train Accuracy: 76.93%, Val Loss: 0.9049, Val Accuracy: 65.81%\n",
      "Epoch [116/250], Train Loss: 0.6110, Train Accuracy: 76.07%, Val Loss: 0.8769, Val Accuracy: 67.95%\n",
      "Epoch [117/250], Train Loss: 0.6168, Train Accuracy: 75.74%, Val Loss: 0.8633, Val Accuracy: 67.52%\n",
      "Epoch [118/250], Train Loss: 0.5859, Train Accuracy: 76.88%, Val Loss: 0.8576, Val Accuracy: 65.38%\n",
      "Epoch [119/250], Train Loss: 0.6026, Train Accuracy: 76.22%, Val Loss: 0.9397, Val Accuracy: 63.25%\n",
      "Epoch [120/250], Train Loss: 0.6219, Train Accuracy: 74.88%, Val Loss: 0.8017, Val Accuracy: 65.38%\n",
      "Epoch [121/250], Train Loss: 0.5972, Train Accuracy: 76.26%, Val Loss: 0.8597, Val Accuracy: 63.25%\n",
      "Epoch [122/250], Train Loss: 0.5976, Train Accuracy: 76.98%, Val Loss: 0.8977, Val Accuracy: 65.38%\n",
      "Epoch [123/250], Train Loss: 0.5778, Train Accuracy: 77.41%, Val Loss: 0.8892, Val Accuracy: 64.53%\n",
      "Epoch [124/250], Train Loss: 0.5928, Train Accuracy: 76.98%, Val Loss: 0.9117, Val Accuracy: 62.82%\n",
      "Epoch [125/250], Train Loss: 0.5742, Train Accuracy: 77.79%, Val Loss: 0.8148, Val Accuracy: 64.10%\n",
      "Epoch [126/250], Train Loss: 0.5843, Train Accuracy: 76.93%, Val Loss: 0.9967, Val Accuracy: 63.68%\n",
      "Epoch [127/250], Train Loss: 0.5967, Train Accuracy: 76.07%, Val Loss: 0.9036, Val Accuracy: 64.53%\n",
      "Epoch [128/250], Train Loss: 0.5770, Train Accuracy: 78.03%, Val Loss: 0.8871, Val Accuracy: 62.82%\n",
      "Epoch [129/250], Train Loss: 0.5825, Train Accuracy: 77.22%, Val Loss: 0.9145, Val Accuracy: 62.82%\n",
      "Epoch [130/250], Train Loss: 0.5701, Train Accuracy: 77.55%, Val Loss: 0.8593, Val Accuracy: 66.67%\n",
      "Epoch [131/250], Train Loss: 0.5670, Train Accuracy: 78.03%, Val Loss: 0.8421, Val Accuracy: 65.81%\n",
      "Epoch [132/250], Train Loss: 0.5550, Train Accuracy: 79.17%, Val Loss: 0.7522, Val Accuracy: 69.23%\n",
      "Epoch [133/250], Train Loss: 0.5599, Train Accuracy: 78.27%, Val Loss: 0.8482, Val Accuracy: 68.80%\n",
      "Epoch [134/250], Train Loss: 0.5478, Train Accuracy: 78.88%, Val Loss: 0.8131, Val Accuracy: 68.80%\n",
      "Epoch [135/250], Train Loss: 0.5513, Train Accuracy: 78.03%, Val Loss: 0.8117, Val Accuracy: 69.23%\n",
      "Epoch [136/250], Train Loss: 0.5371, Train Accuracy: 80.03%, Val Loss: 0.9398, Val Accuracy: 64.10%\n",
      "Epoch [137/250], Train Loss: 0.5335, Train Accuracy: 79.46%, Val Loss: 0.8069, Val Accuracy: 66.24%\n",
      "Epoch [138/250], Train Loss: 0.5666, Train Accuracy: 78.50%, Val Loss: 0.7995, Val Accuracy: 66.67%\n",
      "Epoch [139/250], Train Loss: 0.5842, Train Accuracy: 77.84%, Val Loss: 0.8034, Val Accuracy: 65.81%\n",
      "Epoch [140/250], Train Loss: 0.5439, Train Accuracy: 79.65%, Val Loss: 0.7955, Val Accuracy: 67.95%\n",
      "Epoch [141/250], Train Loss: 0.5374, Train Accuracy: 79.22%, Val Loss: 0.9186, Val Accuracy: 63.68%\n",
      "Epoch [142/250], Train Loss: 0.5632, Train Accuracy: 78.36%, Val Loss: 0.8244, Val Accuracy: 66.67%\n",
      "Epoch [143/250], Train Loss: 0.5156, Train Accuracy: 79.74%, Val Loss: 0.8974, Val Accuracy: 64.10%\n",
      "Epoch [144/250], Train Loss: 0.5217, Train Accuracy: 80.41%, Val Loss: 0.8667, Val Accuracy: 68.38%\n",
      "Epoch [145/250], Train Loss: 0.5509, Train Accuracy: 78.69%, Val Loss: 0.9855, Val Accuracy: 64.10%\n",
      "Epoch [146/250], Train Loss: 0.5653, Train Accuracy: 78.12%, Val Loss: 0.9502, Val Accuracy: 65.38%\n",
      "Epoch [147/250], Train Loss: 0.5477, Train Accuracy: 79.69%, Val Loss: 0.9070, Val Accuracy: 66.24%\n",
      "Epoch [148/250], Train Loss: 0.5587, Train Accuracy: 78.69%, Val Loss: 0.9445, Val Accuracy: 63.68%\n",
      "Epoch [149/250], Train Loss: 0.5205, Train Accuracy: 80.55%, Val Loss: 0.7918, Val Accuracy: 68.80%\n",
      "Epoch [150/250], Train Loss: 0.4880, Train Accuracy: 81.27%, Val Loss: 0.9024, Val Accuracy: 64.53%\n",
      "Epoch [151/250], Train Loss: 0.4891, Train Accuracy: 81.65%, Val Loss: 0.8719, Val Accuracy: 69.23%\n",
      "Epoch [152/250], Train Loss: 0.5427, Train Accuracy: 78.31%, Val Loss: 0.8712, Val Accuracy: 68.80%\n",
      "Epoch [153/250], Train Loss: 0.5027, Train Accuracy: 81.12%, Val Loss: 0.8991, Val Accuracy: 65.38%\n",
      "Epoch [154/250], Train Loss: 0.5115, Train Accuracy: 79.74%, Val Loss: 0.8096, Val Accuracy: 65.38%\n",
      "Epoch [155/250], Train Loss: 0.5207, Train Accuracy: 80.79%, Val Loss: 0.8593, Val Accuracy: 65.81%\n",
      "Epoch [156/250], Train Loss: 0.5190, Train Accuracy: 80.46%, Val Loss: 0.7654, Val Accuracy: 68.80%\n",
      "Epoch [157/250], Train Loss: 0.5116, Train Accuracy: 80.31%, Val Loss: 0.8757, Val Accuracy: 65.38%\n",
      "Epoch [158/250], Train Loss: 0.5086, Train Accuracy: 79.89%, Val Loss: 0.9610, Val Accuracy: 64.53%\n",
      "Epoch [159/250], Train Loss: 0.5222, Train Accuracy: 79.79%, Val Loss: 0.8931, Val Accuracy: 66.67%\n",
      "Epoch [160/250], Train Loss: 0.5112, Train Accuracy: 80.46%, Val Loss: 0.8759, Val Accuracy: 64.53%\n",
      "Epoch [161/250], Train Loss: 0.5250, Train Accuracy: 79.36%, Val Loss: 0.8778, Val Accuracy: 66.24%\n",
      "Epoch [162/250], Train Loss: 0.5136, Train Accuracy: 80.17%, Val Loss: 0.8772, Val Accuracy: 66.24%\n",
      "Epoch [163/250], Train Loss: 0.4889, Train Accuracy: 81.55%, Val Loss: 0.9534, Val Accuracy: 64.96%\n",
      "Epoch [164/250], Train Loss: 0.5237, Train Accuracy: 80.03%, Val Loss: 0.8803, Val Accuracy: 67.52%\n",
      "Epoch [165/250], Train Loss: 0.5207, Train Accuracy: 79.69%, Val Loss: 0.8190, Val Accuracy: 68.80%\n",
      "Epoch [166/250], Train Loss: 0.4853, Train Accuracy: 82.36%, Val Loss: 0.9578, Val Accuracy: 64.53%\n",
      "Epoch [167/250], Train Loss: 0.4894, Train Accuracy: 80.70%, Val Loss: 0.9268, Val Accuracy: 66.67%\n",
      "Epoch [168/250], Train Loss: 0.5158, Train Accuracy: 80.60%, Val Loss: 0.9910, Val Accuracy: 65.38%\n",
      "Epoch [169/250], Train Loss: 0.5096, Train Accuracy: 80.93%, Val Loss: 0.8553, Val Accuracy: 65.81%\n",
      "Epoch [170/250], Train Loss: 0.4781, Train Accuracy: 81.03%, Val Loss: 0.8470, Val Accuracy: 67.52%\n",
      "Epoch [171/250], Train Loss: 0.4800, Train Accuracy: 81.51%, Val Loss: 0.8155, Val Accuracy: 67.95%\n",
      "Epoch [172/250], Train Loss: 0.4970, Train Accuracy: 80.12%, Val Loss: 0.8093, Val Accuracy: 70.09%\n",
      "Epoch [173/250], Train Loss: 0.4802, Train Accuracy: 82.08%, Val Loss: 0.9795, Val Accuracy: 63.25%\n",
      "Epoch [174/250], Train Loss: 0.5170, Train Accuracy: 79.89%, Val Loss: 0.9696, Val Accuracy: 63.68%\n",
      "Epoch [175/250], Train Loss: 0.4969, Train Accuracy: 81.12%, Val Loss: 0.8118, Val Accuracy: 67.52%\n",
      "Epoch [176/250], Train Loss: 0.4455, Train Accuracy: 83.51%, Val Loss: 0.8852, Val Accuracy: 67.09%\n",
      "Epoch [177/250], Train Loss: 0.5085, Train Accuracy: 80.60%, Val Loss: 0.9285, Val Accuracy: 64.53%\n",
      "Epoch [178/250], Train Loss: 0.4921, Train Accuracy: 80.27%, Val Loss: 1.0534, Val Accuracy: 64.53%\n",
      "Epoch [179/250], Train Loss: 0.4735, Train Accuracy: 81.74%, Val Loss: 0.9926, Val Accuracy: 66.24%\n",
      "Epoch [180/250], Train Loss: 0.4850, Train Accuracy: 81.17%, Val Loss: 0.8786, Val Accuracy: 66.67%\n",
      "Epoch [181/250], Train Loss: 0.4616, Train Accuracy: 82.32%, Val Loss: 0.8925, Val Accuracy: 66.24%\n",
      "Epoch [182/250], Train Loss: 0.4561, Train Accuracy: 82.89%, Val Loss: 0.9006, Val Accuracy: 66.24%\n",
      "Epoch [183/250], Train Loss: 0.4726, Train Accuracy: 81.60%, Val Loss: 1.0419, Val Accuracy: 63.68%\n",
      "Epoch [184/250], Train Loss: 0.4931, Train Accuracy: 80.74%, Val Loss: 0.8321, Val Accuracy: 68.80%\n",
      "Epoch [185/250], Train Loss: 0.4678, Train Accuracy: 81.84%, Val Loss: 0.9450, Val Accuracy: 65.81%\n",
      "Epoch [186/250], Train Loss: 0.4402, Train Accuracy: 83.98%, Val Loss: 0.8725, Val Accuracy: 68.80%\n",
      "Epoch [187/250], Train Loss: 0.4509, Train Accuracy: 82.17%, Val Loss: 0.9415, Val Accuracy: 68.80%\n",
      "Epoch [188/250], Train Loss: 0.4469, Train Accuracy: 82.94%, Val Loss: 1.0265, Val Accuracy: 66.67%\n",
      "Epoch [189/250], Train Loss: 0.4846, Train Accuracy: 81.70%, Val Loss: 1.0716, Val Accuracy: 64.96%\n",
      "Epoch [190/250], Train Loss: 0.4689, Train Accuracy: 81.65%, Val Loss: 0.9464, Val Accuracy: 66.67%\n",
      "Epoch [191/250], Train Loss: 0.4927, Train Accuracy: 81.03%, Val Loss: 0.9017, Val Accuracy: 67.52%\n",
      "Epoch [192/250], Train Loss: 0.4534, Train Accuracy: 83.32%, Val Loss: 0.9895, Val Accuracy: 64.53%\n",
      "Epoch [193/250], Train Loss: 0.4709, Train Accuracy: 82.27%, Val Loss: 0.8806, Val Accuracy: 67.95%\n",
      "Epoch [194/250], Train Loss: 0.4622, Train Accuracy: 82.98%, Val Loss: 0.9540, Val Accuracy: 66.67%\n",
      "Epoch [195/250], Train Loss: 0.4670, Train Accuracy: 81.65%, Val Loss: 1.0352, Val Accuracy: 64.53%\n",
      "Epoch [196/250], Train Loss: 0.4672, Train Accuracy: 83.17%, Val Loss: 0.8954, Val Accuracy: 67.09%\n",
      "Epoch [197/250], Train Loss: 0.4461, Train Accuracy: 82.79%, Val Loss: 0.7970, Val Accuracy: 70.09%\n",
      "Epoch [198/250], Train Loss: 0.4373, Train Accuracy: 83.51%, Val Loss: 1.0006, Val Accuracy: 66.24%\n",
      "Epoch [199/250], Train Loss: 0.4468, Train Accuracy: 83.37%, Val Loss: 0.9078, Val Accuracy: 69.66%\n",
      "Epoch [200/250], Train Loss: 0.4043, Train Accuracy: 84.89%, Val Loss: 1.0298, Val Accuracy: 63.68%\n",
      "Epoch [201/250], Train Loss: 0.4252, Train Accuracy: 84.08%, Val Loss: 0.9355, Val Accuracy: 70.09%\n",
      "Epoch [202/250], Train Loss: 0.4502, Train Accuracy: 82.98%, Val Loss: 1.0309, Val Accuracy: 65.38%\n",
      "Epoch [203/250], Train Loss: 0.4546, Train Accuracy: 82.75%, Val Loss: 1.0463, Val Accuracy: 64.96%\n",
      "Epoch [204/250], Train Loss: 0.4426, Train Accuracy: 84.37%, Val Loss: 0.8350, Val Accuracy: 70.09%\n",
      "Epoch [205/250], Train Loss: 0.4427, Train Accuracy: 82.55%, Val Loss: 1.0726, Val Accuracy: 66.67%\n",
      "Epoch [206/250], Train Loss: 0.4571, Train Accuracy: 82.94%, Val Loss: 0.8088, Val Accuracy: 68.38%\n",
      "Epoch [207/250], Train Loss: 0.4501, Train Accuracy: 82.65%, Val Loss: 0.9406, Val Accuracy: 64.53%\n",
      "Epoch [208/250], Train Loss: 0.4563, Train Accuracy: 82.55%, Val Loss: 0.9230, Val Accuracy: 63.25%\n",
      "Epoch [209/250], Train Loss: 0.4413, Train Accuracy: 82.60%, Val Loss: 0.9426, Val Accuracy: 66.24%\n",
      "Epoch [210/250], Train Loss: 0.4512, Train Accuracy: 82.65%, Val Loss: 0.8922, Val Accuracy: 66.67%\n",
      "Epoch [211/250], Train Loss: 0.4223, Train Accuracy: 83.46%, Val Loss: 0.8438, Val Accuracy: 70.09%\n",
      "Epoch [212/250], Train Loss: 0.4523, Train Accuracy: 82.84%, Val Loss: 0.9572, Val Accuracy: 64.53%\n",
      "Epoch [213/250], Train Loss: 0.4167, Train Accuracy: 84.37%, Val Loss: 0.9962, Val Accuracy: 65.38%\n",
      "Epoch [214/250], Train Loss: 0.4142, Train Accuracy: 84.08%, Val Loss: 0.8662, Val Accuracy: 68.80%\n",
      "Epoch [215/250], Train Loss: 0.4168, Train Accuracy: 83.94%, Val Loss: 1.1358, Val Accuracy: 60.26%\n",
      "Epoch [216/250], Train Loss: 0.4293, Train Accuracy: 82.89%, Val Loss: 1.0247, Val Accuracy: 64.96%\n",
      "Epoch [217/250], Train Loss: 0.4263, Train Accuracy: 83.70%, Val Loss: 1.0362, Val Accuracy: 67.52%\n",
      "Epoch [218/250], Train Loss: 0.4236, Train Accuracy: 83.75%, Val Loss: 0.9415, Val Accuracy: 66.67%\n",
      "Epoch [219/250], Train Loss: 0.4261, Train Accuracy: 83.65%, Val Loss: 1.0148, Val Accuracy: 65.38%\n",
      "Epoch [220/250], Train Loss: 0.4324, Train Accuracy: 83.84%, Val Loss: 0.9574, Val Accuracy: 66.67%\n",
      "Epoch [221/250], Train Loss: 0.4276, Train Accuracy: 83.70%, Val Loss: 0.9163, Val Accuracy: 69.23%\n",
      "Epoch [222/250], Train Loss: 0.4250, Train Accuracy: 84.18%, Val Loss: 0.8891, Val Accuracy: 68.80%\n",
      "Epoch [223/250], Train Loss: 0.4256, Train Accuracy: 83.98%, Val Loss: 0.9805, Val Accuracy: 64.96%\n",
      "Epoch [224/250], Train Loss: 0.4332, Train Accuracy: 83.79%, Val Loss: 1.1366, Val Accuracy: 61.11%\n",
      "Epoch [225/250], Train Loss: 0.4072, Train Accuracy: 84.84%, Val Loss: 0.9373, Val Accuracy: 65.38%\n",
      "Epoch [226/250], Train Loss: 0.4073, Train Accuracy: 84.60%, Val Loss: 0.8956, Val Accuracy: 69.66%\n",
      "Epoch [227/250], Train Loss: 0.4197, Train Accuracy: 83.27%, Val Loss: 1.0407, Val Accuracy: 64.10%\n",
      "Epoch [228/250], Train Loss: 0.4169, Train Accuracy: 84.37%, Val Loss: 0.7927, Val Accuracy: 67.09%\n",
      "Epoch [229/250], Train Loss: 0.3973, Train Accuracy: 85.27%, Val Loss: 0.9698, Val Accuracy: 66.24%\n",
      "Epoch [230/250], Train Loss: 0.4262, Train Accuracy: 83.89%, Val Loss: 0.9452, Val Accuracy: 68.38%\n",
      "Epoch [231/250], Train Loss: 0.4355, Train Accuracy: 82.94%, Val Loss: 0.9632, Val Accuracy: 66.24%\n",
      "Epoch [232/250], Train Loss: 0.4170, Train Accuracy: 84.32%, Val Loss: 0.8991, Val Accuracy: 67.09%\n",
      "Epoch [233/250], Train Loss: 0.4048, Train Accuracy: 84.51%, Val Loss: 0.9656, Val Accuracy: 66.67%\n",
      "Epoch [234/250], Train Loss: 0.3935, Train Accuracy: 85.75%, Val Loss: 1.1368, Val Accuracy: 64.10%\n",
      "Epoch [235/250], Train Loss: 0.3693, Train Accuracy: 85.61%, Val Loss: 0.9865, Val Accuracy: 66.24%\n",
      "Epoch [236/250], Train Loss: 0.4210, Train Accuracy: 84.18%, Val Loss: 0.9569, Val Accuracy: 68.80%\n",
      "Epoch [237/250], Train Loss: 0.4048, Train Accuracy: 84.51%, Val Loss: 0.9550, Val Accuracy: 66.24%\n",
      "Epoch [238/250], Train Loss: 0.4029, Train Accuracy: 85.18%, Val Loss: 0.8249, Val Accuracy: 68.80%\n",
      "Epoch [239/250], Train Loss: 0.4083, Train Accuracy: 84.37%, Val Loss: 0.8310, Val Accuracy: 70.09%\n",
      "Epoch [240/250], Train Loss: 0.4237, Train Accuracy: 83.98%, Val Loss: 0.8634, Val Accuracy: 69.66%\n",
      "Epoch [241/250], Train Loss: 0.3845, Train Accuracy: 85.51%, Val Loss: 0.9214, Val Accuracy: 66.67%\n",
      "Epoch [242/250], Train Loss: 0.4041, Train Accuracy: 85.46%, Val Loss: 1.0319, Val Accuracy: 65.38%\n",
      "Epoch [243/250], Train Loss: 0.4284, Train Accuracy: 83.84%, Val Loss: 0.8359, Val Accuracy: 66.67%\n",
      "Epoch [244/250], Train Loss: 0.3909, Train Accuracy: 85.94%, Val Loss: 0.8199, Val Accuracy: 70.51%\n",
      "Epoch [245/250], Train Loss: 0.4100, Train Accuracy: 84.37%, Val Loss: 0.9313, Val Accuracy: 69.66%\n",
      "Epoch [246/250], Train Loss: 0.3950, Train Accuracy: 84.94%, Val Loss: 1.0290, Val Accuracy: 66.24%\n",
      "Epoch [247/250], Train Loss: 0.3991, Train Accuracy: 84.65%, Val Loss: 0.8618, Val Accuracy: 67.95%\n",
      "Epoch [248/250], Train Loss: 0.3843, Train Accuracy: 85.61%, Val Loss: 0.8735, Val Accuracy: 68.38%\n",
      "Epoch [249/250], Train Loss: 0.4056, Train Accuracy: 84.75%, Val Loss: 0.8523, Val Accuracy: 70.09%\n",
      "Epoch [250/250], Train Loss: 0.3892, Train Accuracy: 84.27%, Val Loss: 1.1040, Val Accuracy: 65.38%\n",
      "Final accuracy on test set: 68.46%\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        \n",
    "        #First CNN Layer\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, output_channel, padding=0, kernel_size=20, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #First LSTM layers with bidirectional\n",
    "        self.lstm1 = nn.LSTM(output_channel, hidden_size=lstm_hidden_dim1, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        #Second CNN Layer\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(lstm_hidden_dim1*2, output_channel2, padding=0, kernel_size=10, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel2),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #Second Lstm layer with bidirectional\n",
    "        self.lstm2 = nn.LSTM(output_channel2, lstm_hidden_dim2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(lstm_hidden_dim2 * 2 * 3, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.cnn(x)  # Apply CNN\n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM (batch_size, seq_len, num_features)\n",
    "        \n",
    "        x, _ = self.lstm1(x)  # First LSTM layer\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute back for CNN\n",
    "        x = self.cnn2(x)  # Apply second CNN layer\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM\n",
    "        \n",
    "        x, _ = self.lstm2(x) # Second LSTM layer\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.contiguous().view(x.size(0), -1)  # Flatten for FC layer\n",
    "        x = self.fc(x)  # Apply fully connected layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_normal_(param)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.zeros_(param)\n",
    "                        n = param.size(0)\n",
    "                        param[n // 4:n // 2].data.fill_(1.0)  # Set forget gate bias to 1.0\n",
    "\n",
    "input_channels = 22  \n",
    "output_channel = 40\n",
    "output_channel2 = 30\n",
    "lstm_hidden_dim1 = 70\n",
    "lstm_hidden_dim2 = 50\n",
    "num_classes = 4  \n",
    "\n",
    "# Instantiate the model\n",
    "model = CNNLSTM(input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007, weight_decay=.002)\n",
    "# Training the model\n",
    "num_epochs = 250\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "# Testing Phase\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\t\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final accuracy on test set: {final_accuracy:.2f}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
