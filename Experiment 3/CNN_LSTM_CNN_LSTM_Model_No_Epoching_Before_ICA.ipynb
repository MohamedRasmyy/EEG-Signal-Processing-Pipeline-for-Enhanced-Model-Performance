{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the preprocessed data\n",
    "X = np.load('X_all_No_Epoching_Before_ICA.npy')\n",
    "Y = np.load('Y_all_No_Epoching_Before_ICA.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (2098, 22, 1126)\n",
      "Validation set shape: (234, 22, 1126)\n",
      "Test set shape: (260, 22, 1126)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=.1,random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "X_train_flatten = X_train.reshape(-1, X_train.shape[-1])  # Shape: (num_train_epochs * num_channels, seq_len)\n",
    "X_val_flatten = X_val.reshape(-1, X_val.shape[-1])        # Validation set\n",
    "X_test_flatten = X_test.reshape(-1, X_test.shape[-1])  # Shape: (num_test_epochs * num_channels, seq_len)\n",
    "\n",
    "mean = X_train_flatten.mean(axis=0)  # Compute the mean for each feature\n",
    "X_train_centered = X_train_flatten - mean\n",
    "X_val_centered = X_val_flatten - mean  # Center validation data using train set mean\n",
    "X_test_centered = X_test_flatten - mean  # Apply the same mean to X_test\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # Disable mean subtraction since we already did it\n",
    "X_train_scaled = scaler.fit_transform(X_train_centered)  # Fit on X_train\n",
    "X_val_scaled = scaler.transform(X_val_centered)  # Apply the same scaler to validation data\n",
    "X_test_scaled = scaler.transform(X_test_centered)  # Transform X_test using the same scaler\n",
    "\n",
    "X_train_final = X_train_scaled.reshape(X_train.shape)  # Shape: (num_train_epochs, num_channels, seq_len)\n",
    "X_val_final = X_val_scaled.reshape(X_val.shape)        # Shape: (num_val_epochs, num_channels, seq_len)\n",
    "X_test_final = X_test_scaled.reshape(X_test.shape)  # Shape: (num_test_epochs, num_channels, seq_len)\n",
    "\n",
    "print(\"Train set shape:\", X_train_final.shape)\n",
    "print(\"Validation set shape:\", X_val_final.shape)\n",
    "print(\"Test set shape:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert Numpy Arrays to PyTorch Tensors\n",
    "X_train1=torch.tensor(X_train_final,dtype=torch.float32)\n",
    "X_val1=torch.tensor(X_val_final,dtype=torch.float32)\n",
    "X_test1=torch.tensor(X_test_final,dtype=torch.float32)\n",
    "\n",
    "y_train1=torch.tensor(y_train,dtype=torch.long)\n",
    "y_val1=torch.tensor(y_val,dtype=torch.long)\n",
    "y_test1=torch.tensor(y_test,dtype=torch.long)\n",
    "\n",
    "# 2. Create TensorDatasets for Train, Validation, and Test Sets\n",
    "train_dataset=TensorDataset(X_train1,y_train1)\n",
    "val_dataset=TensorDataset(X_val1,y_val1)\n",
    "test_dataset=TensorDataset(X_test1,y_test1)\n",
    "\n",
    "# 3. Create DataLoaders for Batch Processing\n",
    "train_loader=DataLoader(train_dataset,batch_size=100,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=100,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Train Loss: 1.4426, Train Accuracy: 25.31%, Val Loss: 1.3739, Val Accuracy: 32.05%\n",
      "Epoch [2/250], Train Loss: 1.4285, Train Accuracy: 25.98%, Val Loss: 1.3691, Val Accuracy: 29.91%\n",
      "Epoch [3/250], Train Loss: 1.4167, Train Accuracy: 26.60%, Val Loss: 1.3627, Val Accuracy: 27.78%\n",
      "Epoch [4/250], Train Loss: 1.4007, Train Accuracy: 27.50%, Val Loss: 1.3674, Val Accuracy: 28.63%\n",
      "Epoch [5/250], Train Loss: 1.3989, Train Accuracy: 28.31%, Val Loss: 1.3616, Val Accuracy: 29.91%\n",
      "Epoch [6/250], Train Loss: 1.3784, Train Accuracy: 29.17%, Val Loss: 1.3411, Val Accuracy: 37.18%\n",
      "Epoch [7/250], Train Loss: 1.3624, Train Accuracy: 29.79%, Val Loss: 1.3202, Val Accuracy: 38.89%\n",
      "Epoch [8/250], Train Loss: 1.3537, Train Accuracy: 31.94%, Val Loss: 1.3211, Val Accuracy: 37.61%\n",
      "Epoch [9/250], Train Loss: 1.3334, Train Accuracy: 34.22%, Val Loss: 1.2842, Val Accuracy: 38.03%\n",
      "Epoch [10/250], Train Loss: 1.3227, Train Accuracy: 36.42%, Val Loss: 1.2842, Val Accuracy: 34.62%\n",
      "Epoch [11/250], Train Loss: 1.3196, Train Accuracy: 34.70%, Val Loss: 1.3252, Val Accuracy: 34.62%\n",
      "Epoch [12/250], Train Loss: 1.2880, Train Accuracy: 38.47%, Val Loss: 1.2306, Val Accuracy: 38.46%\n",
      "Epoch [13/250], Train Loss: 1.2779, Train Accuracy: 39.08%, Val Loss: 1.2749, Val Accuracy: 37.18%\n",
      "Epoch [14/250], Train Loss: 1.2655, Train Accuracy: 39.80%, Val Loss: 1.1950, Val Accuracy: 42.74%\n",
      "Epoch [15/250], Train Loss: 1.2547, Train Accuracy: 41.66%, Val Loss: 1.2273, Val Accuracy: 43.16%\n",
      "Epoch [16/250], Train Loss: 1.2398, Train Accuracy: 42.33%, Val Loss: 1.2064, Val Accuracy: 42.31%\n",
      "Epoch [17/250], Train Loss: 1.2123, Train Accuracy: 44.90%, Val Loss: 1.1196, Val Accuracy: 42.74%\n",
      "Epoch [18/250], Train Loss: 1.2079, Train Accuracy: 44.66%, Val Loss: 1.4994, Val Accuracy: 36.32%\n",
      "Epoch [19/250], Train Loss: 1.1831, Train Accuracy: 44.80%, Val Loss: 1.1034, Val Accuracy: 50.00%\n",
      "Epoch [20/250], Train Loss: 1.1624, Train Accuracy: 47.76%, Val Loss: 1.0873, Val Accuracy: 48.72%\n",
      "Epoch [21/250], Train Loss: 1.1611, Train Accuracy: 46.85%, Val Loss: 1.0317, Val Accuracy: 52.99%\n",
      "Epoch [22/250], Train Loss: 1.1535, Train Accuracy: 48.24%, Val Loss: 1.0691, Val Accuracy: 50.00%\n",
      "Epoch [23/250], Train Loss: 1.1348, Train Accuracy: 50.05%, Val Loss: 1.0958, Val Accuracy: 48.29%\n",
      "Epoch [24/250], Train Loss: 1.1176, Train Accuracy: 50.19%, Val Loss: 1.2099, Val Accuracy: 44.44%\n",
      "Epoch [25/250], Train Loss: 1.1030, Train Accuracy: 51.62%, Val Loss: 1.1237, Val Accuracy: 47.86%\n",
      "Epoch [26/250], Train Loss: 1.1015, Train Accuracy: 51.43%, Val Loss: 1.0583, Val Accuracy: 52.56%\n",
      "Epoch [27/250], Train Loss: 1.0747, Train Accuracy: 52.72%, Val Loss: 1.0294, Val Accuracy: 52.99%\n",
      "Epoch [28/250], Train Loss: 1.0908, Train Accuracy: 50.91%, Val Loss: 1.0264, Val Accuracy: 49.15%\n",
      "Epoch [29/250], Train Loss: 1.0423, Train Accuracy: 53.10%, Val Loss: 1.1415, Val Accuracy: 46.58%\n",
      "Epoch [30/250], Train Loss: 1.0492, Train Accuracy: 52.86%, Val Loss: 0.9726, Val Accuracy: 51.71%\n",
      "Epoch [31/250], Train Loss: 1.0343, Train Accuracy: 55.48%, Val Loss: 1.0131, Val Accuracy: 54.70%\n",
      "Epoch [32/250], Train Loss: 1.0361, Train Accuracy: 54.86%, Val Loss: 1.0061, Val Accuracy: 52.56%\n",
      "Epoch [33/250], Train Loss: 1.0186, Train Accuracy: 55.58%, Val Loss: 0.9525, Val Accuracy: 54.27%\n",
      "Epoch [34/250], Train Loss: 1.0035, Train Accuracy: 55.86%, Val Loss: 0.9154, Val Accuracy: 57.26%\n",
      "Epoch [35/250], Train Loss: 1.0277, Train Accuracy: 54.67%, Val Loss: 0.9365, Val Accuracy: 56.41%\n",
      "Epoch [36/250], Train Loss: 1.0095, Train Accuracy: 56.34%, Val Loss: 0.9309, Val Accuracy: 55.13%\n",
      "Epoch [37/250], Train Loss: 0.9976, Train Accuracy: 56.48%, Val Loss: 0.9175, Val Accuracy: 58.55%\n",
      "Epoch [38/250], Train Loss: 1.0059, Train Accuracy: 55.48%, Val Loss: 0.8990, Val Accuracy: 57.26%\n",
      "Epoch [39/250], Train Loss: 0.9849, Train Accuracy: 57.72%, Val Loss: 0.9737, Val Accuracy: 55.98%\n",
      "Epoch [40/250], Train Loss: 0.9883, Train Accuracy: 57.58%, Val Loss: 1.0229, Val Accuracy: 52.56%\n",
      "Epoch [41/250], Train Loss: 0.9755, Train Accuracy: 58.48%, Val Loss: 0.8939, Val Accuracy: 58.12%\n",
      "Epoch [42/250], Train Loss: 0.9394, Train Accuracy: 60.77%, Val Loss: 1.0092, Val Accuracy: 52.99%\n",
      "Epoch [43/250], Train Loss: 0.9609, Train Accuracy: 60.15%, Val Loss: 0.9373, Val Accuracy: 54.70%\n",
      "Epoch [44/250], Train Loss: 0.9539, Train Accuracy: 59.06%, Val Loss: 0.9462, Val Accuracy: 57.26%\n",
      "Epoch [45/250], Train Loss: 0.9295, Train Accuracy: 60.77%, Val Loss: 1.0764, Val Accuracy: 50.00%\n",
      "Epoch [46/250], Train Loss: 0.9331, Train Accuracy: 60.06%, Val Loss: 0.9389, Val Accuracy: 54.70%\n",
      "Epoch [47/250], Train Loss: 0.9552, Train Accuracy: 59.77%, Val Loss: 0.9359, Val Accuracy: 57.69%\n",
      "Epoch [48/250], Train Loss: 0.9426, Train Accuracy: 58.34%, Val Loss: 0.8959, Val Accuracy: 58.55%\n",
      "Epoch [49/250], Train Loss: 0.9099, Train Accuracy: 62.92%, Val Loss: 0.8053, Val Accuracy: 64.96%\n",
      "Epoch [50/250], Train Loss: 0.8829, Train Accuracy: 62.39%, Val Loss: 1.0645, Val Accuracy: 55.98%\n",
      "Epoch [51/250], Train Loss: 0.9104, Train Accuracy: 61.30%, Val Loss: 0.9010, Val Accuracy: 58.55%\n",
      "Epoch [52/250], Train Loss: 0.8962, Train Accuracy: 61.73%, Val Loss: 0.8711, Val Accuracy: 62.39%\n",
      "Epoch [53/250], Train Loss: 0.8821, Train Accuracy: 63.87%, Val Loss: 0.9476, Val Accuracy: 57.69%\n",
      "Epoch [54/250], Train Loss: 0.8687, Train Accuracy: 64.63%, Val Loss: 0.8955, Val Accuracy: 61.97%\n",
      "Epoch [55/250], Train Loss: 0.8847, Train Accuracy: 63.58%, Val Loss: 0.9865, Val Accuracy: 53.85%\n",
      "Epoch [56/250], Train Loss: 0.8660, Train Accuracy: 64.06%, Val Loss: 0.8631, Val Accuracy: 61.97%\n",
      "Epoch [57/250], Train Loss: 0.8462, Train Accuracy: 66.06%, Val Loss: 0.9828, Val Accuracy: 58.55%\n",
      "Epoch [58/250], Train Loss: 0.8488, Train Accuracy: 65.63%, Val Loss: 0.8425, Val Accuracy: 64.53%\n",
      "Epoch [59/250], Train Loss: 0.8413, Train Accuracy: 66.02%, Val Loss: 0.8080, Val Accuracy: 63.25%\n",
      "Epoch [60/250], Train Loss: 0.8458, Train Accuracy: 64.30%, Val Loss: 0.8989, Val Accuracy: 63.25%\n",
      "Epoch [61/250], Train Loss: 0.8162, Train Accuracy: 66.35%, Val Loss: 0.9221, Val Accuracy: 58.12%\n",
      "Epoch [62/250], Train Loss: 0.8344, Train Accuracy: 65.25%, Val Loss: 0.8450, Val Accuracy: 65.81%\n",
      "Epoch [63/250], Train Loss: 0.8203, Train Accuracy: 66.97%, Val Loss: 0.8191, Val Accuracy: 62.82%\n",
      "Epoch [64/250], Train Loss: 0.8265, Train Accuracy: 65.87%, Val Loss: 0.9338, Val Accuracy: 61.97%\n",
      "Epoch [65/250], Train Loss: 0.8135, Train Accuracy: 66.87%, Val Loss: 0.8699, Val Accuracy: 61.11%\n",
      "Epoch [66/250], Train Loss: 0.8245, Train Accuracy: 66.02%, Val Loss: 0.8427, Val Accuracy: 64.96%\n",
      "Epoch [67/250], Train Loss: 0.8079, Train Accuracy: 66.63%, Val Loss: 0.8976, Val Accuracy: 60.26%\n",
      "Epoch [68/250], Train Loss: 0.7838, Train Accuracy: 68.68%, Val Loss: 0.8990, Val Accuracy: 61.54%\n",
      "Epoch [69/250], Train Loss: 0.8122, Train Accuracy: 65.92%, Val Loss: 0.9568, Val Accuracy: 55.56%\n",
      "Epoch [70/250], Train Loss: 0.8187, Train Accuracy: 67.73%, Val Loss: 0.8470, Val Accuracy: 61.11%\n",
      "Epoch [71/250], Train Loss: 0.7783, Train Accuracy: 68.35%, Val Loss: 0.9784, Val Accuracy: 54.27%\n",
      "Epoch [72/250], Train Loss: 0.7828, Train Accuracy: 69.40%, Val Loss: 0.9362, Val Accuracy: 57.69%\n",
      "Epoch [73/250], Train Loss: 0.7826, Train Accuracy: 69.02%, Val Loss: 0.9723, Val Accuracy: 58.97%\n",
      "Epoch [74/250], Train Loss: 0.7720, Train Accuracy: 69.64%, Val Loss: 0.8938, Val Accuracy: 60.68%\n",
      "Epoch [75/250], Train Loss: 0.7792, Train Accuracy: 68.35%, Val Loss: 0.8061, Val Accuracy: 63.68%\n",
      "Epoch [76/250], Train Loss: 0.7587, Train Accuracy: 70.31%, Val Loss: 0.8926, Val Accuracy: 62.82%\n",
      "Epoch [77/250], Train Loss: 0.7845, Train Accuracy: 69.11%, Val Loss: 0.9093, Val Accuracy: 61.11%\n",
      "Epoch [78/250], Train Loss: 0.7866, Train Accuracy: 67.78%, Val Loss: 0.8765, Val Accuracy: 60.26%\n",
      "Epoch [79/250], Train Loss: 0.7632, Train Accuracy: 69.26%, Val Loss: 0.9842, Val Accuracy: 57.26%\n",
      "Epoch [80/250], Train Loss: 0.7379, Train Accuracy: 70.26%, Val Loss: 0.8231, Val Accuracy: 65.38%\n",
      "Epoch [81/250], Train Loss: 0.7584, Train Accuracy: 69.64%, Val Loss: 0.8404, Val Accuracy: 63.25%\n",
      "Epoch [82/250], Train Loss: 0.7115, Train Accuracy: 72.16%, Val Loss: 0.9010, Val Accuracy: 59.40%\n",
      "Epoch [83/250], Train Loss: 0.7440, Train Accuracy: 69.73%, Val Loss: 0.8847, Val Accuracy: 63.25%\n",
      "Epoch [84/250], Train Loss: 0.7369, Train Accuracy: 70.78%, Val Loss: 0.9020, Val Accuracy: 64.10%\n",
      "Epoch [85/250], Train Loss: 0.7268, Train Accuracy: 71.40%, Val Loss: 0.9278, Val Accuracy: 58.12%\n",
      "Epoch [86/250], Train Loss: 0.7033, Train Accuracy: 72.02%, Val Loss: 0.8451, Val Accuracy: 63.68%\n",
      "Epoch [87/250], Train Loss: 0.7108, Train Accuracy: 70.92%, Val Loss: 0.9121, Val Accuracy: 61.97%\n",
      "Epoch [88/250], Train Loss: 0.7330, Train Accuracy: 71.16%, Val Loss: 0.8368, Val Accuracy: 64.96%\n",
      "Epoch [89/250], Train Loss: 0.7088, Train Accuracy: 71.88%, Val Loss: 0.7990, Val Accuracy: 68.38%\n",
      "Epoch [90/250], Train Loss: 0.7075, Train Accuracy: 71.88%, Val Loss: 0.8337, Val Accuracy: 63.25%\n",
      "Epoch [91/250], Train Loss: 0.6938, Train Accuracy: 72.45%, Val Loss: 0.9127, Val Accuracy: 61.54%\n",
      "Epoch [92/250], Train Loss: 0.7118, Train Accuracy: 71.69%, Val Loss: 0.8750, Val Accuracy: 59.83%\n",
      "Epoch [93/250], Train Loss: 0.7249, Train Accuracy: 71.21%, Val Loss: 0.8036, Val Accuracy: 68.80%\n",
      "Epoch [94/250], Train Loss: 0.7031, Train Accuracy: 72.12%, Val Loss: 0.8755, Val Accuracy: 61.54%\n",
      "Epoch [95/250], Train Loss: 0.6866, Train Accuracy: 72.59%, Val Loss: 0.8961, Val Accuracy: 62.39%\n",
      "Epoch [96/250], Train Loss: 0.6992, Train Accuracy: 72.21%, Val Loss: 0.8389, Val Accuracy: 61.54%\n",
      "Epoch [97/250], Train Loss: 0.6837, Train Accuracy: 74.59%, Val Loss: 0.8125, Val Accuracy: 63.25%\n",
      "Epoch [98/250], Train Loss: 0.6990, Train Accuracy: 72.40%, Val Loss: 0.8629, Val Accuracy: 63.68%\n",
      "Epoch [99/250], Train Loss: 0.6764, Train Accuracy: 73.31%, Val Loss: 0.9791, Val Accuracy: 60.26%\n",
      "Epoch [100/250], Train Loss: 0.6748, Train Accuracy: 72.93%, Val Loss: 0.8155, Val Accuracy: 61.11%\n",
      "Epoch [101/250], Train Loss: 0.6604, Train Accuracy: 73.07%, Val Loss: 0.8743, Val Accuracy: 63.68%\n",
      "Epoch [102/250], Train Loss: 0.6646, Train Accuracy: 74.17%, Val Loss: 0.9087, Val Accuracy: 61.97%\n",
      "Epoch [103/250], Train Loss: 0.6847, Train Accuracy: 73.31%, Val Loss: 0.7692, Val Accuracy: 67.95%\n",
      "Epoch [104/250], Train Loss: 0.6530, Train Accuracy: 73.59%, Val Loss: 0.8478, Val Accuracy: 64.53%\n",
      "Epoch [105/250], Train Loss: 0.6540, Train Accuracy: 74.26%, Val Loss: 0.8430, Val Accuracy: 64.10%\n",
      "Epoch [106/250], Train Loss: 0.6630, Train Accuracy: 72.69%, Val Loss: 1.0220, Val Accuracy: 62.39%\n",
      "Epoch [107/250], Train Loss: 0.6583, Train Accuracy: 73.50%, Val Loss: 0.9064, Val Accuracy: 60.26%\n",
      "Epoch [108/250], Train Loss: 0.6394, Train Accuracy: 74.79%, Val Loss: 0.8868, Val Accuracy: 66.24%\n",
      "Epoch [109/250], Train Loss: 0.6669, Train Accuracy: 74.59%, Val Loss: 0.8478, Val Accuracy: 64.10%\n",
      "Epoch [110/250], Train Loss: 0.6530, Train Accuracy: 73.74%, Val Loss: 0.8217, Val Accuracy: 65.81%\n",
      "Epoch [111/250], Train Loss: 0.6401, Train Accuracy: 74.88%, Val Loss: 0.8110, Val Accuracy: 66.67%\n",
      "Epoch [112/250], Train Loss: 0.6359, Train Accuracy: 74.12%, Val Loss: 0.9328, Val Accuracy: 61.54%\n",
      "Epoch [113/250], Train Loss: 0.6672, Train Accuracy: 73.69%, Val Loss: 0.9127, Val Accuracy: 61.54%\n",
      "Epoch [114/250], Train Loss: 0.6224, Train Accuracy: 76.64%, Val Loss: 0.8278, Val Accuracy: 64.53%\n",
      "Epoch [115/250], Train Loss: 0.6485, Train Accuracy: 73.78%, Val Loss: 0.8299, Val Accuracy: 64.10%\n",
      "Epoch [116/250], Train Loss: 0.6367, Train Accuracy: 73.55%, Val Loss: 0.8510, Val Accuracy: 66.24%\n",
      "Epoch [117/250], Train Loss: 0.6202, Train Accuracy: 76.07%, Val Loss: 0.8093, Val Accuracy: 69.23%\n",
      "Epoch [118/250], Train Loss: 0.6324, Train Accuracy: 75.69%, Val Loss: 0.7819, Val Accuracy: 66.24%\n",
      "Epoch [119/250], Train Loss: 0.6188, Train Accuracy: 75.98%, Val Loss: 0.7327, Val Accuracy: 68.80%\n",
      "Epoch [120/250], Train Loss: 0.6136, Train Accuracy: 76.45%, Val Loss: 0.7022, Val Accuracy: 68.80%\n",
      "Epoch [121/250], Train Loss: 0.6383, Train Accuracy: 74.07%, Val Loss: 0.7819, Val Accuracy: 67.95%\n",
      "Epoch [122/250], Train Loss: 0.6470, Train Accuracy: 73.64%, Val Loss: 0.8347, Val Accuracy: 67.95%\n",
      "Epoch [123/250], Train Loss: 0.6268, Train Accuracy: 75.55%, Val Loss: 0.8294, Val Accuracy: 64.96%\n",
      "Epoch [124/250], Train Loss: 0.6222, Train Accuracy: 75.41%, Val Loss: 0.8959, Val Accuracy: 63.25%\n",
      "Epoch [125/250], Train Loss: 0.6251, Train Accuracy: 75.83%, Val Loss: 0.7876, Val Accuracy: 65.81%\n",
      "Epoch [126/250], Train Loss: 0.5775, Train Accuracy: 77.17%, Val Loss: 0.7781, Val Accuracy: 67.09%\n",
      "Epoch [127/250], Train Loss: 0.6009, Train Accuracy: 76.45%, Val Loss: 0.8730, Val Accuracy: 67.09%\n",
      "Epoch [128/250], Train Loss: 0.6057, Train Accuracy: 76.41%, Val Loss: 0.8231, Val Accuracy: 65.38%\n",
      "Epoch [129/250], Train Loss: 0.6131, Train Accuracy: 75.93%, Val Loss: 0.8339, Val Accuracy: 65.81%\n",
      "Epoch [130/250], Train Loss: 0.5976, Train Accuracy: 76.84%, Val Loss: 0.7510, Val Accuracy: 68.80%\n",
      "Epoch [131/250], Train Loss: 0.6141, Train Accuracy: 76.45%, Val Loss: 0.8405, Val Accuracy: 64.53%\n",
      "Epoch [132/250], Train Loss: 0.6049, Train Accuracy: 76.26%, Val Loss: 0.8410, Val Accuracy: 66.67%\n",
      "Epoch [133/250], Train Loss: 0.5846, Train Accuracy: 77.31%, Val Loss: 0.8603, Val Accuracy: 61.11%\n",
      "Epoch [134/250], Train Loss: 0.5869, Train Accuracy: 76.98%, Val Loss: 0.8823, Val Accuracy: 66.24%\n",
      "Epoch [135/250], Train Loss: 0.5916, Train Accuracy: 77.03%, Val Loss: 0.7480, Val Accuracy: 67.09%\n",
      "Epoch [136/250], Train Loss: 0.5442, Train Accuracy: 79.22%, Val Loss: 0.8354, Val Accuracy: 69.23%\n",
      "Epoch [137/250], Train Loss: 0.5889, Train Accuracy: 76.93%, Val Loss: 0.8070, Val Accuracy: 67.09%\n",
      "Epoch [138/250], Train Loss: 0.5718, Train Accuracy: 77.31%, Val Loss: 0.8330, Val Accuracy: 65.38%\n",
      "Epoch [139/250], Train Loss: 0.5855, Train Accuracy: 77.12%, Val Loss: 0.8041, Val Accuracy: 66.67%\n",
      "Epoch [140/250], Train Loss: 0.5940, Train Accuracy: 76.84%, Val Loss: 0.8054, Val Accuracy: 66.67%\n",
      "Epoch [141/250], Train Loss: 0.5669, Train Accuracy: 77.98%, Val Loss: 0.7431, Val Accuracy: 68.80%\n",
      "Epoch [142/250], Train Loss: 0.5793, Train Accuracy: 77.07%, Val Loss: 0.8183, Val Accuracy: 64.53%\n",
      "Epoch [143/250], Train Loss: 0.5680, Train Accuracy: 77.98%, Val Loss: 0.8081, Val Accuracy: 65.81%\n",
      "Epoch [144/250], Train Loss: 0.5698, Train Accuracy: 77.84%, Val Loss: 0.8516, Val Accuracy: 65.38%\n",
      "Epoch [145/250], Train Loss: 0.5486, Train Accuracy: 78.31%, Val Loss: 0.9612, Val Accuracy: 61.97%\n",
      "Epoch [146/250], Train Loss: 0.5386, Train Accuracy: 79.46%, Val Loss: 0.9170, Val Accuracy: 64.96%\n",
      "Epoch [147/250], Train Loss: 0.5736, Train Accuracy: 77.12%, Val Loss: 0.8408, Val Accuracy: 64.53%\n",
      "Epoch [148/250], Train Loss: 0.5727, Train Accuracy: 78.50%, Val Loss: 0.7399, Val Accuracy: 70.51%\n",
      "Epoch [149/250], Train Loss: 0.5510, Train Accuracy: 79.03%, Val Loss: 0.7494, Val Accuracy: 66.67%\n",
      "Epoch [150/250], Train Loss: 0.5267, Train Accuracy: 78.98%, Val Loss: 0.8198, Val Accuracy: 67.52%\n",
      "Epoch [151/250], Train Loss: 0.5605, Train Accuracy: 78.22%, Val Loss: 0.8051, Val Accuracy: 66.67%\n",
      "Epoch [152/250], Train Loss: 0.5333, Train Accuracy: 79.36%, Val Loss: 0.8016, Val Accuracy: 67.95%\n",
      "Epoch [153/250], Train Loss: 0.5344, Train Accuracy: 79.41%, Val Loss: 0.8888, Val Accuracy: 69.23%\n",
      "Epoch [154/250], Train Loss: 0.5454, Train Accuracy: 80.41%, Val Loss: 0.8840, Val Accuracy: 65.81%\n",
      "Epoch [155/250], Train Loss: 0.5702, Train Accuracy: 77.50%, Val Loss: 0.8373, Val Accuracy: 64.10%\n",
      "Epoch [156/250], Train Loss: 0.5577, Train Accuracy: 78.31%, Val Loss: 0.8378, Val Accuracy: 65.81%\n",
      "Epoch [157/250], Train Loss: 0.5258, Train Accuracy: 79.79%, Val Loss: 0.9869, Val Accuracy: 67.95%\n",
      "Epoch [158/250], Train Loss: 0.5511, Train Accuracy: 79.08%, Val Loss: 0.8495, Val Accuracy: 64.53%\n",
      "Epoch [159/250], Train Loss: 0.5765, Train Accuracy: 77.45%, Val Loss: 0.7961, Val Accuracy: 68.80%\n",
      "Epoch [160/250], Train Loss: 0.5469, Train Accuracy: 78.60%, Val Loss: 0.7992, Val Accuracy: 66.24%\n",
      "Epoch [161/250], Train Loss: 0.5369, Train Accuracy: 78.84%, Val Loss: 0.8575, Val Accuracy: 67.09%\n",
      "Epoch [162/250], Train Loss: 0.5066, Train Accuracy: 80.31%, Val Loss: 0.7599, Val Accuracy: 67.52%\n",
      "Epoch [163/250], Train Loss: 0.5279, Train Accuracy: 79.27%, Val Loss: 0.7593, Val Accuracy: 70.51%\n",
      "Epoch [164/250], Train Loss: 0.5442, Train Accuracy: 78.12%, Val Loss: 0.7128, Val Accuracy: 71.79%\n",
      "Epoch [165/250], Train Loss: 0.5164, Train Accuracy: 79.55%, Val Loss: 0.7555, Val Accuracy: 69.23%\n",
      "Epoch [166/250], Train Loss: 0.4961, Train Accuracy: 80.98%, Val Loss: 0.8836, Val Accuracy: 66.67%\n",
      "Epoch [167/250], Train Loss: 0.5647, Train Accuracy: 77.84%, Val Loss: 0.8873, Val Accuracy: 67.09%\n",
      "Epoch [168/250], Train Loss: 0.5231, Train Accuracy: 79.55%, Val Loss: 0.7663, Val Accuracy: 65.38%\n",
      "Epoch [169/250], Train Loss: 0.5127, Train Accuracy: 80.27%, Val Loss: 0.7056, Val Accuracy: 71.79%\n",
      "Epoch [170/250], Train Loss: 0.5057, Train Accuracy: 80.27%, Val Loss: 0.7961, Val Accuracy: 67.52%\n",
      "Epoch [171/250], Train Loss: 0.5105, Train Accuracy: 80.31%, Val Loss: 0.8135, Val Accuracy: 68.38%\n",
      "Epoch [172/250], Train Loss: 0.5202, Train Accuracy: 79.84%, Val Loss: 0.8776, Val Accuracy: 67.09%\n",
      "Epoch [173/250], Train Loss: 0.5183, Train Accuracy: 80.17%, Val Loss: 0.8330, Val Accuracy: 66.24%\n",
      "Epoch [174/250], Train Loss: 0.5505, Train Accuracy: 78.36%, Val Loss: 0.9399, Val Accuracy: 65.81%\n",
      "Epoch [175/250], Train Loss: 0.5213, Train Accuracy: 79.41%, Val Loss: 0.8767, Val Accuracy: 66.67%\n",
      "Epoch [176/250], Train Loss: 0.4972, Train Accuracy: 81.22%, Val Loss: 0.8099, Val Accuracy: 67.09%\n",
      "Epoch [177/250], Train Loss: 0.4964, Train Accuracy: 81.36%, Val Loss: 0.9754, Val Accuracy: 65.81%\n",
      "Epoch [178/250], Train Loss: 0.4966, Train Accuracy: 82.22%, Val Loss: 0.8783, Val Accuracy: 64.96%\n",
      "Epoch [179/250], Train Loss: 0.4930, Train Accuracy: 81.46%, Val Loss: 0.8596, Val Accuracy: 64.10%\n",
      "Epoch [180/250], Train Loss: 0.4996, Train Accuracy: 80.74%, Val Loss: 0.9122, Val Accuracy: 63.68%\n",
      "Epoch [181/250], Train Loss: 0.4660, Train Accuracy: 81.74%, Val Loss: 0.8280, Val Accuracy: 63.25%\n",
      "Epoch [182/250], Train Loss: 0.4928, Train Accuracy: 81.03%, Val Loss: 0.8591, Val Accuracy: 64.96%\n",
      "Epoch [183/250], Train Loss: 0.5279, Train Accuracy: 79.69%, Val Loss: 0.7957, Val Accuracy: 68.38%\n",
      "Epoch [184/250], Train Loss: 0.4854, Train Accuracy: 81.46%, Val Loss: 0.8016, Val Accuracy: 69.23%\n",
      "Epoch [185/250], Train Loss: 0.4969, Train Accuracy: 80.74%, Val Loss: 0.8582, Val Accuracy: 68.38%\n",
      "Epoch [186/250], Train Loss: 0.5210, Train Accuracy: 80.22%, Val Loss: 0.9899, Val Accuracy: 67.09%\n",
      "Epoch [187/250], Train Loss: 0.5004, Train Accuracy: 81.12%, Val Loss: 0.8773, Val Accuracy: 66.24%\n",
      "Epoch [188/250], Train Loss: 0.5073, Train Accuracy: 80.84%, Val Loss: 0.8687, Val Accuracy: 65.81%\n",
      "Epoch [189/250], Train Loss: 0.5254, Train Accuracy: 79.98%, Val Loss: 0.8759, Val Accuracy: 64.53%\n",
      "Epoch [190/250], Train Loss: 0.4747, Train Accuracy: 81.94%, Val Loss: 0.7512, Val Accuracy: 69.66%\n",
      "Epoch [191/250], Train Loss: 0.5061, Train Accuracy: 80.51%, Val Loss: 0.8012, Val Accuracy: 69.66%\n",
      "Epoch [192/250], Train Loss: 0.5031, Train Accuracy: 80.36%, Val Loss: 0.7319, Val Accuracy: 69.23%\n",
      "Epoch [193/250], Train Loss: 0.4953, Train Accuracy: 81.74%, Val Loss: 0.8140, Val Accuracy: 68.38%\n",
      "Epoch [194/250], Train Loss: 0.5040, Train Accuracy: 80.41%, Val Loss: 0.7914, Val Accuracy: 68.38%\n",
      "Epoch [195/250], Train Loss: 0.4751, Train Accuracy: 81.60%, Val Loss: 0.9019, Val Accuracy: 64.53%\n",
      "Epoch [196/250], Train Loss: 0.5096, Train Accuracy: 81.08%, Val Loss: 0.8571, Val Accuracy: 67.95%\n",
      "Epoch [197/250], Train Loss: 0.4660, Train Accuracy: 81.98%, Val Loss: 0.8775, Val Accuracy: 66.67%\n",
      "Epoch [198/250], Train Loss: 0.4785, Train Accuracy: 82.13%, Val Loss: 0.8130, Val Accuracy: 69.66%\n",
      "Epoch [199/250], Train Loss: 0.5077, Train Accuracy: 81.17%, Val Loss: 0.8157, Val Accuracy: 69.66%\n",
      "Epoch [200/250], Train Loss: 0.4380, Train Accuracy: 83.22%, Val Loss: 0.8352, Val Accuracy: 67.52%\n",
      "Epoch [201/250], Train Loss: 0.4693, Train Accuracy: 82.13%, Val Loss: 0.7377, Val Accuracy: 66.67%\n",
      "Epoch [202/250], Train Loss: 0.4674, Train Accuracy: 81.89%, Val Loss: 0.7780, Val Accuracy: 68.38%\n",
      "Epoch [203/250], Train Loss: 0.4598, Train Accuracy: 82.51%, Val Loss: 0.9219, Val Accuracy: 62.82%\n",
      "Epoch [204/250], Train Loss: 0.4535, Train Accuracy: 82.46%, Val Loss: 0.8441, Val Accuracy: 66.24%\n",
      "Epoch [205/250], Train Loss: 0.4521, Train Accuracy: 82.98%, Val Loss: 0.8748, Val Accuracy: 67.09%\n",
      "Epoch [206/250], Train Loss: 0.4683, Train Accuracy: 82.51%, Val Loss: 0.7494, Val Accuracy: 71.37%\n",
      "Epoch [207/250], Train Loss: 0.4472, Train Accuracy: 83.37%, Val Loss: 1.0135, Val Accuracy: 64.10%\n",
      "Epoch [208/250], Train Loss: 0.4717, Train Accuracy: 82.22%, Val Loss: 0.7780, Val Accuracy: 71.37%\n",
      "Epoch [209/250], Train Loss: 0.4893, Train Accuracy: 80.22%, Val Loss: 0.8012, Val Accuracy: 69.66%\n",
      "Epoch [210/250], Train Loss: 0.4861, Train Accuracy: 81.84%, Val Loss: 0.8865, Val Accuracy: 64.10%\n",
      "Epoch [211/250], Train Loss: 0.4495, Train Accuracy: 82.51%, Val Loss: 0.8812, Val Accuracy: 67.09%\n",
      "Epoch [212/250], Train Loss: 0.4835, Train Accuracy: 81.74%, Val Loss: 0.8979, Val Accuracy: 66.67%\n",
      "Epoch [213/250], Train Loss: 0.4587, Train Accuracy: 82.51%, Val Loss: 0.9255, Val Accuracy: 67.09%\n",
      "Epoch [214/250], Train Loss: 0.4241, Train Accuracy: 83.51%, Val Loss: 0.7203, Val Accuracy: 73.08%\n",
      "Epoch [215/250], Train Loss: 0.4340, Train Accuracy: 83.17%, Val Loss: 0.9245, Val Accuracy: 62.39%\n",
      "Epoch [216/250], Train Loss: 0.4784, Train Accuracy: 81.65%, Val Loss: 0.9521, Val Accuracy: 64.10%\n",
      "Epoch [217/250], Train Loss: 0.4526, Train Accuracy: 83.27%, Val Loss: 0.8696, Val Accuracy: 64.96%\n",
      "Epoch [218/250], Train Loss: 0.4494, Train Accuracy: 82.27%, Val Loss: 0.9108, Val Accuracy: 63.25%\n",
      "Epoch [219/250], Train Loss: 0.4488, Train Accuracy: 83.17%, Val Loss: 0.7720, Val Accuracy: 66.67%\n",
      "Epoch [220/250], Train Loss: 0.4731, Train Accuracy: 81.08%, Val Loss: 0.7930, Val Accuracy: 67.52%\n",
      "Epoch [221/250], Train Loss: 0.4414, Train Accuracy: 82.94%, Val Loss: 0.7350, Val Accuracy: 67.52%\n",
      "Epoch [222/250], Train Loss: 0.4508, Train Accuracy: 82.89%, Val Loss: 0.9543, Val Accuracy: 64.96%\n",
      "Epoch [223/250], Train Loss: 0.4887, Train Accuracy: 81.32%, Val Loss: 0.7719, Val Accuracy: 68.80%\n",
      "Epoch [224/250], Train Loss: 0.4805, Train Accuracy: 81.41%, Val Loss: 0.8970, Val Accuracy: 66.67%\n",
      "Epoch [225/250], Train Loss: 0.4240, Train Accuracy: 84.56%, Val Loss: 0.8189, Val Accuracy: 68.38%\n",
      "Epoch [226/250], Train Loss: 0.4444, Train Accuracy: 84.08%, Val Loss: 0.8377, Val Accuracy: 68.80%\n",
      "Epoch [227/250], Train Loss: 0.4684, Train Accuracy: 82.13%, Val Loss: 0.7922, Val Accuracy: 68.80%\n",
      "Epoch [228/250], Train Loss: 0.4376, Train Accuracy: 83.75%, Val Loss: 0.7490, Val Accuracy: 70.09%\n",
      "Epoch [229/250], Train Loss: 0.4278, Train Accuracy: 83.56%, Val Loss: 0.8583, Val Accuracy: 68.38%\n",
      "Epoch [230/250], Train Loss: 0.4485, Train Accuracy: 82.60%, Val Loss: 0.8202, Val Accuracy: 68.80%\n",
      "Epoch [231/250], Train Loss: 0.4261, Train Accuracy: 83.22%, Val Loss: 0.8016, Val Accuracy: 67.09%\n",
      "Epoch [232/250], Train Loss: 0.4524, Train Accuracy: 83.08%, Val Loss: 0.7993, Val Accuracy: 69.66%\n",
      "Epoch [233/250], Train Loss: 0.4282, Train Accuracy: 82.60%, Val Loss: 0.7867, Val Accuracy: 70.09%\n",
      "Epoch [234/250], Train Loss: 0.4301, Train Accuracy: 83.32%, Val Loss: 0.8487, Val Accuracy: 68.80%\n",
      "Epoch [235/250], Train Loss: 0.4084, Train Accuracy: 84.70%, Val Loss: 0.7326, Val Accuracy: 72.65%\n",
      "Epoch [236/250], Train Loss: 0.4616, Train Accuracy: 81.98%, Val Loss: 0.8774, Val Accuracy: 66.67%\n",
      "Epoch [237/250], Train Loss: 0.4502, Train Accuracy: 82.70%, Val Loss: 1.0692, Val Accuracy: 62.82%\n",
      "Epoch [238/250], Train Loss: 0.4409, Train Accuracy: 83.08%, Val Loss: 0.8866, Val Accuracy: 67.95%\n",
      "Epoch [239/250], Train Loss: 0.4460, Train Accuracy: 82.84%, Val Loss: 0.8375, Val Accuracy: 68.80%\n",
      "Epoch [240/250], Train Loss: 0.4518, Train Accuracy: 82.41%, Val Loss: 0.9774, Val Accuracy: 64.10%\n",
      "Epoch [241/250], Train Loss: 0.4378, Train Accuracy: 83.27%, Val Loss: 0.7391, Val Accuracy: 70.51%\n",
      "Epoch [242/250], Train Loss: 0.4598, Train Accuracy: 82.36%, Val Loss: 0.7396, Val Accuracy: 70.94%\n",
      "Epoch [243/250], Train Loss: 0.4228, Train Accuracy: 84.65%, Val Loss: 0.7751, Val Accuracy: 69.23%\n",
      "Epoch [244/250], Train Loss: 0.4139, Train Accuracy: 84.03%, Val Loss: 0.8332, Val Accuracy: 70.51%\n",
      "Epoch [245/250], Train Loss: 0.4330, Train Accuracy: 83.65%, Val Loss: 0.8704, Val Accuracy: 67.09%\n",
      "Epoch [246/250], Train Loss: 0.4608, Train Accuracy: 82.79%, Val Loss: 0.9037, Val Accuracy: 69.23%\n",
      "Epoch [247/250], Train Loss: 0.4269, Train Accuracy: 83.41%, Val Loss: 0.9285, Val Accuracy: 63.25%\n",
      "Epoch [248/250], Train Loss: 0.4097, Train Accuracy: 84.13%, Val Loss: 0.9171, Val Accuracy: 63.25%\n",
      "Epoch [249/250], Train Loss: 0.4184, Train Accuracy: 83.56%, Val Loss: 0.8171, Val Accuracy: 70.09%\n",
      "Epoch [250/250], Train Loss: 0.4029, Train Accuracy: 85.13%, Val Loss: 0.7948, Val Accuracy: 67.52%\n",
      "Final accuracy on test set: 69.23%\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        \n",
    "        #First CNN Layer\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, output_channel, padding=0, kernel_size=20, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #First LSTM layers with bidirectional\n",
    "        self.lstm1 = nn.LSTM(output_channel, hidden_size=lstm_hidden_dim1, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        #Second CNN Layer\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(lstm_hidden_dim1*2, output_channel2, padding=0, kernel_size=10, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_channel2),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        #Second Lstm layer with bidirectional\n",
    "        self.lstm2 = nn.LSTM(output_channel2, lstm_hidden_dim2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(lstm_hidden_dim2 * 2 * 3, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.cnn(x)  # Apply CNN\n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM (batch_size, seq_len, num_features)\n",
    "        \n",
    "        x, _ = self.lstm1(x)  # First LSTM layer\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute back for CNN\n",
    "        x = self.cnn2(x)  # Apply second CNN layer\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Permute for LSTM\n",
    "        \n",
    "        x, _ = self.lstm2(x) # Second LSTM layer\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.contiguous().view(x.size(0), -1)  # Flatten for FC layer\n",
    "        x = self.fc(x)  # Apply fully connected layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_normal_(param)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.zeros_(param)\n",
    "                        n = param.size(0)\n",
    "                        param[n // 4:n // 2].data.fill_(1.0)  # Set forget gate bias to 1.0\n",
    "\n",
    "input_channels = 22  \n",
    "output_channel = 40\n",
    "output_channel2 = 30\n",
    "lstm_hidden_dim1 = 70\n",
    "lstm_hidden_dim2 = 50\n",
    "num_classes = 4  \n",
    "\n",
    "# Instantiate the model\n",
    "model = CNNLSTM(input_channels, output_channel, lstm_hidden_dim1, lstm_hidden_dim2, output_channel2, num_classes)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007, weight_decay=.002)\n",
    "# Training the model\n",
    "num_epochs = 250\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "# Testing Phase\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\t\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final accuracy on test set: {final_accuracy:.2f}%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
